{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Electric load forecasting with Deep Learning",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'smart-meters-in-london:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4021%2F3684057%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240314%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240314T163712Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D2f5ac54159b9b9392f3c8a776491c987ee5e79c15ddfaa4276576c4853107088dd42e81b1dae33eeda08fcb3b0632fb0de97b075e68ccb9f55bdf242b0df37909b7c91ab4488607324f4d85dbaf9d344fb52d228b062e27a22c41712260b5c3e9f5f6cca5a3779a3716d2782bd2581fd46f18b952992e926edee34ea6c703cf0105b42c0b5bb4db42e7802ec7a008c23dd42496ff315cfadc8bf16ddc3838e586fb0bf6d8b015c4ccc56626caf4ad7acd219d4b81efcee5e2b0d4bc2cc4d5684670bc6cbf84af77187e27ecd74a622fa35186fee4566361c35835bc0209656429f3d31ac3284109f64ac946824ff22b253a8cc24e3f5b6955917bedbef22216d'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "3cAbaHrd02xS"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Short-term residential load forecasting with Deep Learning\n",
        "\n",
        "London households smart meter data\n",
        "\n",
        "Thanks to my collaborator [Aaron Epel](http://www.linkedin.com/in/aaronepel/)!\n"
      ],
      "metadata": {
        "id": "u26dSkvJ02xV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from pandas_profiling import ProfileReport\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import IPython\n",
        "import IPython.display\n",
        "import glob\n",
        "import time\n",
        "import pickle\n",
        "import sys\n",
        "from sklearn.inspection import permutation_importance\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "randomState = 42 # tip of the cap to Douglas Adams"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:01:12.629086Z",
          "iopub.execute_input": "2023-10-25T14:01:12.631171Z",
          "iopub.status.idle": "2023-10-25T14:01:12.641129Z",
          "shell.execute_reply.started": "2023-10-25T14:01:12.63112Z",
          "shell.execute_reply": "2023-10-25T14:01:12.639736Z"
        },
        "trusted": true,
        "id": "XF3eJjpK02xX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "F9RiuvsI02xX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load half-hourly electric usage data\n",
        "...for ~5k smart meters in London\n",
        "[SmartMeter Energy Consumption Data in London Households](https://data.london.gov.uk/dataset/smartmeter-energy-use-data-in-london-households)"
      ],
      "metadata": {
        "id": "F4NlO3Xm02xY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load half-hourly electric usage data\n",
        "# takes about four minutes, need to find somerthing faster like Dask?\n",
        "# https://data.london.gov.uk/dataset/smartmeter-energy-use-data-in-london-households\n",
        "# Get CSV files list from a folder\n",
        "path = '/kaggle/input/smart-meters-in-london/halfhourly_dataset/halfhourly_dataset'\n",
        "csv_files = glob.glob(path + \"/*.csv\")\n",
        "\n",
        "# Read each CSV file into DataFrame\n",
        "# This creates a list of dataframes\n",
        "start_time = time.time()\n",
        "df_list = (pd.read_csv(file, parse_dates=[\"tstp\"]) for file in csv_files)\n",
        "print('%s seconds' % (time.time() - start_time))\n",
        "\n",
        "# Concatenate all DataFrames\n",
        "start_time = time.time()\n",
        "d = pd.concat(df_list, ignore_index=True)\n",
        "print('%s seconds' % (time.time() - start_time))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:01:12.643626Z",
          "iopub.execute_input": "2023-10-25T14:01:12.644025Z",
          "iopub.status.idle": "2023-10-25T14:06:32.735449Z",
          "shell.execute_reply.started": "2023-10-25T14:01:12.643993Z",
          "shell.execute_reply": "2023-10-25T14:06:32.734152Z"
        },
        "trusted": true,
        "id": "ErqpOJbu02xY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d.describe()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:06:32.737005Z",
          "iopub.execute_input": "2023-10-25T14:06:32.737356Z",
          "iopub.status.idle": "2023-10-25T14:08:16.946356Z",
          "shell.execute_reply.started": "2023-10-25T14:06:32.737325Z",
          "shell.execute_reply": "2023-10-25T14:08:16.945096Z"
        },
        "trusted": true,
        "id": "cwBLezpK02xZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load hourly weather data"
      ],
      "metadata": {
        "id": "MwCL-uXh02xZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load hourly weather data\n",
        "# https://data.london.gov.uk/dataset/smartmeter-energy-use-data-in-london-households\n",
        "weatherData = pd.read_csv('/kaggle/input/smart-meters-in-london/weather_hourly_darksky.csv', parse_dates=[\"time\"])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:08:16.948698Z",
          "iopub.execute_input": "2023-10-25T14:08:16.94903Z",
          "iopub.status.idle": "2023-10-25T14:08:17.048779Z",
          "shell.execute_reply.started": "2023-10-25T14:08:16.949001Z",
          "shell.execute_reply": "2023-10-25T14:08:17.047764Z"
        },
        "trusted": true,
        "id": "7PbZwt6o02xZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weatherData.describe()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:08:17.050356Z",
          "iopub.execute_input": "2023-10-25T14:08:17.051043Z",
          "iopub.status.idle": "2023-10-25T14:08:17.10422Z",
          "shell.execute_reply.started": "2023-10-25T14:08:17.050986Z",
          "shell.execute_reply": "2023-10-25T14:08:17.103051Z"
        },
        "trusted": true,
        "id": "ZciyMKuk02xZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weatherData.info()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:08:17.105896Z",
          "iopub.execute_input": "2023-10-25T14:08:17.106237Z",
          "iopub.status.idle": "2023-10-25T14:08:17.148951Z",
          "shell.execute_reply.started": "2023-10-25T14:08:17.106209Z",
          "shell.execute_reply": "2023-10-25T14:08:17.147788Z"
        },
        "trusted": true,
        "id": "jHyvN36k02xa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data pre-processing and cleaning"
      ],
      "metadata": {
        "id": "DWPeTCdj02xa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Weather data: convert text attributes to string datatype"
      ],
      "metadata": {
        "id": "e-hCa2Mj02xa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weatherData = weatherData.astype({'precipType':'string', 'icon':'string', 'summary':'string'})"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:08:17.15081Z",
          "iopub.execute_input": "2023-10-25T14:08:17.151143Z",
          "iopub.status.idle": "2023-10-25T14:08:17.162473Z",
          "shell.execute_reply.started": "2023-10-25T14:08:17.151114Z",
          "shell.execute_reply": "2023-10-25T14:08:17.161488Z"
        },
        "trusted": true,
        "id": "3uiUpTSP02xa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas_profiling import ProfileReport\n",
        "\n",
        "profile = ProfileReport(weatherData, tsmode=True, sortby=\"time\")\n",
        "profile.to_file('weatherData profile_report.html')\n",
        "# profile"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:08:17.163706Z",
          "iopub.execute_input": "2023-10-25T14:08:17.164024Z",
          "iopub.status.idle": "2023-10-25T14:09:33.62299Z",
          "shell.execute_reply.started": "2023-10-25T14:08:17.163996Z",
          "shell.execute_reply": "2023-10-25T14:09:33.621592Z"
        },
        "trusted": true,
        "id": "_i3iRSqU02xa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Identify and remove weather records not exactly on the hour"
      ],
      "metadata": {
        "id": "Rf4803La02xb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# inspect and remove records not exactly on the hour\n",
        "offRecs = weatherData.query(\"time.dt.minute != 0 or time.dt.second != 0\")\n",
        "print('Records not exactly on the half-hour:\\n ', offRecs)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:09:33.627468Z",
          "iopub.execute_input": "2023-10-25T14:09:33.627952Z",
          "iopub.status.idle": "2023-10-25T14:09:33.660801Z",
          "shell.execute_reply.started": "2023-10-25T14:09:33.627914Z",
          "shell.execute_reply": "2023-10-25T14:09:33.6593Z"
        },
        "trusted": true,
        "id": "mhz0cgR802xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# select weather data features of interest\n",
        "weatherUpsample = weatherData[['time','temperature', 'dewPoint']].copy()\n",
        "# weatherUpsample = weatherData[['time','temperature', 'dewPoint', 'pressure', 'humidity']].copy()\n",
        "# pressure and humidity removed due to permutation feature importance results\n",
        "weatherUpsample = weatherUpsample.sort_values(by=['time'])\n",
        "print(weatherUpsample.info())\n",
        "print(weatherUpsample.describe())\n",
        "print(weatherUpsample)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:09:33.663085Z",
          "iopub.execute_input": "2023-10-25T14:09:33.66361Z",
          "iopub.status.idle": "2023-10-25T14:09:33.70375Z",
          "shell.execute_reply.started": "2023-10-25T14:09:33.663563Z",
          "shell.execute_reply": "2023-10-25T14:09:33.702482Z"
        },
        "trusted": true,
        "id": "CMp8H_Ql02xc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upsample weather data to match half-houly sampling rate of load data"
      ],
      "metadata": {
        "id": "jqpD3I8902xc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get the index set up to support the resamle operation\n",
        "weatherUpsample.set_index('time', inplace=True)\n",
        "weatherUpsample.index.rename('time', inplace=True)\n",
        "\n",
        "start_time = time.time()\n",
        "weatherUpsample = weatherUpsample.resample('30Min').mean()\n",
        "\n",
        "# upsample\n",
        "weatherUpsample['temperature'] = weatherUpsample['temperature'].interpolate()\n",
        "weatherUpsample['dewPoint'] = weatherUpsample['dewPoint'].interpolate()\n",
        "# weatherUpsample['pressure'] = weatherUpsample['pressure'].interpolate()\n",
        "# weatherUpsample['humidity'] = weatherUpsample['humidity'].interpolate()\n",
        "\n",
        "print('%s seconds' % (time.time() - start_time))\n",
        "\n",
        "weatherUpsample = weatherUpsample.reset_index(names='DateTime')\n",
        "print(weatherUpsample.info())\n",
        "print(weatherUpsample.describe())\n",
        "print(weatherUpsample)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:09:33.705535Z",
          "iopub.execute_input": "2023-10-25T14:09:33.70596Z",
          "iopub.status.idle": "2023-10-25T14:09:33.78283Z",
          "shell.execute_reply.started": "2023-10-25T14:09:33.705923Z",
          "shell.execute_reply": "2023-10-25T14:09:33.781797Z"
        },
        "trusted": true,
        "id": "Y7Ku64em02xc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save weather data so we don't have to do pre-processing again\n",
        "weatherUpsample.to_csv('/kaggle/working/WeatherDataFinal.csv',index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:09:33.784234Z",
          "iopub.execute_input": "2023-10-25T14:09:33.785142Z",
          "iopub.status.idle": "2023-10-25T14:09:34.109691Z",
          "shell.execute_reply.started": "2023-10-25T14:09:33.785104Z",
          "shell.execute_reply": "2023-10-25T14:09:34.1086Z"
        },
        "trusted": true,
        "id": "hE06NhMn02xc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load pre-processed weather data\n",
        "weatherUpsample = pd.read_csv('/kaggle/working/WeatherDataFinal.csv', parse_dates=[\"DateTime\"])\n",
        "weatherUpsample"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:09:34.111263Z",
          "iopub.execute_input": "2023-10-25T14:09:34.111884Z",
          "iopub.status.idle": "2023-10-25T14:09:34.192589Z",
          "shell.execute_reply.started": "2023-10-25T14:09:34.111849Z",
          "shell.execute_reply": "2023-10-25T14:09:34.191283Z"
        },
        "trusted": true,
        "id": "5Ww9b9Ie02xc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# utility function to nicely format variable names and memory they are consuming\n",
        "import sys\n",
        "def sizeof_fmt(num, suffix='B'):\n",
        "    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n",
        "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
        "        if abs(num) < 1024.0:\n",
        "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
        "        num /= 1024.0\n",
        "    return \"%.1f %s%s\" % (num, 'Yi', suffix)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:09:34.194349Z",
          "iopub.execute_input": "2023-10-25T14:09:34.194796Z",
          "iopub.status.idle": "2023-10-25T14:09:34.203713Z",
          "shell.execute_reply.started": "2023-10-25T14:09:34.194758Z",
          "shell.execute_reply": "2023-10-25T14:09:34.202255Z"
        },
        "trusted": true,
        "id": "d1lod-w-02xc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert smart meter usage datatype to float"
      ],
      "metadata": {
        "id": "-rJyby1X02xd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ~1 minute\n",
        "start_time = time.time()\n",
        "d.iloc[:, 2] = pd.to_numeric(d.iloc[:, 2], errors='coerce')\n",
        "print('%s seconds' % (time.time() - start_time))\n",
        "\n",
        "# rename usage column for easier reference\n",
        "d.rename(columns={d.columns[2]: 'kWhPerHalfHour'}, inplace=True)\n",
        "d.info()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:09:34.205228Z",
          "iopub.execute_input": "2023-10-25T14:09:34.205666Z",
          "iopub.status.idle": "2023-10-25T14:11:22.64962Z",
          "shell.execute_reply.started": "2023-10-25T14:09:34.205618Z",
          "shell.execute_reply": "2023-10-25T14:11:22.648105Z"
        },
        "trusted": true,
        "id": "Baniskte02xd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set timestamp as the index\n",
        "start_time = time.time()\n",
        "d.set_index('tstp')\n",
        "print('%s seconds' % (time.time() - start_time))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:11:22.65147Z",
          "iopub.execute_input": "2023-10-25T14:11:22.652399Z",
          "iopub.status.idle": "2023-10-25T14:11:27.856929Z",
          "shell.execute_reply.started": "2023-10-25T14:11:22.652358Z",
          "shell.execute_reply": "2023-10-25T14:11:27.855329Z"
        },
        "trusted": true,
        "id": "WXDMtlDo02xd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Identify and handle duplicates in the smart meter data"
      ],
      "metadata": {
        "id": "Cq8T0hEt02xd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# about 1.5 minutes\n",
        "start_time = time.time()\n",
        "dupes = d[d.duplicated()]\n",
        "print('dupes', dupes)\n",
        "print('dupes.index', dupes.index)\n",
        "d.drop(index=dupes.index, inplace=True)\n",
        "print('%s seconds' % (time.time() - start_time))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:11:27.858891Z",
          "iopub.execute_input": "2023-10-25T14:11:27.859373Z",
          "iopub.status.idle": "2023-10-25T14:13:28.86164Z",
          "shell.execute_reply.started": "2023-10-25T14:11:27.859333Z",
          "shell.execute_reply": "2023-10-25T14:13:28.860062Z"
        },
        "trusted": true,
        "id": "7WnXLzRC02xd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set index for the usage data to the timestamp column.  Is this necessary?  Can't remember why\n",
        "start_time = time.time()\n",
        "d.set_index('tstp')\n",
        "d.info()\n",
        "print('%s seconds' % (time.time() - start_time))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:13:28.864237Z",
          "iopub.execute_input": "2023-10-25T14:13:28.86486Z",
          "iopub.status.idle": "2023-10-25T14:13:34.089182Z",
          "shell.execute_reply.started": "2023-10-25T14:13:28.864809Z",
          "shell.execute_reply": "2023-10-25T14:13:34.088071Z"
        },
        "trusted": true,
        "id": "-JqWl-US02xd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check what is gobbling RAM\n",
        "for name, size in sorted(((name, sys.getsizeof(value)) for name, value in list(\n",
        "                          locals().items())), key= lambda x: -x[1])[:10]:\n",
        "    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:13:34.09062Z",
          "iopub.execute_input": "2023-10-25T14:13:34.091227Z",
          "iopub.status.idle": "2023-10-25T14:14:16.497588Z",
          "shell.execute_reply.started": "2023-10-25T14:13:34.091193Z",
          "shell.execute_reply": "2023-10-25T14:14:16.49627Z"
        },
        "trusted": true,
        "id": "WFINs89w02xe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis\n",
        "## Visualize smart meter dataset to analyze for quality, completenes and other insights"
      ],
      "metadata": {
        "id": "pkWv9RG_02xe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## grab a random sample of 2% of meters for visualization and analysis"
      ],
      "metadata": {
        "id": "MeMugU6w02xe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rng = np.random.default_rng(randomState)\n",
        "# random_state = np.random.RandomState(randomState)\n",
        "sampleMeters = rng.choice(d.LCLid.unique(), size=int(len(d.LCLid.unique())*0.02), replace=False)\n",
        "print('sampleMeters:\\n', sampleMeters)\n",
        "sample = d[d['LCLid'].isin(sampleMeters)]\n",
        "print('sample:\\n', sample)\n",
        "print(sample.describe())\n",
        "# print(sample.info())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:14:16.499063Z",
          "iopub.execute_input": "2023-10-25T14:14:16.499412Z",
          "iopub.status.idle": "2023-10-25T14:15:06.030456Z",
          "shell.execute_reply.started": "2023-10-25T14:14:16.499382Z",
          "shell.execute_reply": "2023-10-25T14:15:06.02925Z"
        },
        "trusted": true,
        "id": "eu4SdMXy02xe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample.to_csv('/kaggle/working/sampleMeters.csv',index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:15:06.032729Z",
          "iopub.execute_input": "2023-10-25T14:15:06.033125Z",
          "iopub.status.idle": "2023-10-25T14:15:28.879686Z",
          "shell.execute_reply.started": "2023-10-25T14:15:06.033093Z",
          "shell.execute_reply": "2023-10-25T14:15:28.878287Z"
        },
        "trusted": true,
        "id": "ybRylFUf02xe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = pd.read_csv('/kaggle/working/sampleMeters.csv', parse_dates=[\"tstp\"])\n",
        "sample"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:15:28.881492Z",
          "iopub.execute_input": "2023-10-25T14:15:28.882518Z",
          "iopub.status.idle": "2023-10-25T14:15:32.563614Z",
          "shell.execute_reply.started": "2023-10-25T14:15:28.882476Z",
          "shell.execute_reply": "2023-10-25T14:15:32.562139Z"
        },
        "trusted": true,
        "id": "AgaSvuua02xe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Heatmap to visualize meter read coverage and completeness"
      ],
      "metadata": {
        "id": "RDF5R0aw02xf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize meter read coverage and completeness\n",
        "# using a random sample of 2% of meters\n",
        "import matplotlib.ticker as ticker\n",
        "plt.subplots(figsize=(20,5))\n",
        "pivot_table = pd.pivot_table(sample, columns='tstp', index='LCLid', values='kWhPerHalfHour')\n",
        "sns.heatmap(pivot_table, xticklabels=48*30)\n",
        "plt.title('Meter Data Heatmap', size=15)\n",
        "plt.savefig('meter data heatmap.png', format='png')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:15:32.565808Z",
          "iopub.execute_input": "2023-10-25T14:15:32.566271Z",
          "iopub.status.idle": "2023-10-25T14:15:48.238596Z",
          "shell.execute_reply.started": "2023-10-25T14:15:32.566231Z",
          "shell.execute_reply": "2023-10-25T14:15:48.237216Z"
        },
        "trusted": true,
        "id": "GeRqoOjb02xf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "def to_datetime(x):\n",
        "  return pd.to_datetime(x, format='%Y-%m-%d %H:%M')\n",
        "\n",
        "def format_datetime(x):\n",
        "  return x.strftime('%Y-%m-%d %H:%M')\n",
        "\n",
        "# Create a pivot table of the data\n",
        "# pivot_table = pd.pivot_table(sample, columns='tstp', index='LCLid', values='kWhPerHalfHour')\n",
        "\n",
        "# Convert the timestamps to datetime objects\n",
        "pivot_table.columns = pivot_table.columns.map(to_datetime)\n",
        "\n",
        "# Create a heatmap of the data\n",
        "fig, ax = plt.subplots(figsize=(20, 5))\n",
        "sns.heatmap(pivot_table, ax=ax, xticklabels=pivot_table.columns.map(format_datetime))\n",
        "\n",
        "# Set the title and save the figure\n",
        "plt.title('Meter Data Heatmap', size=15)\n",
        "plt.savefig('meter data heatmap.png', format='png')\n",
        "'''"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:15:48.251045Z",
          "iopub.execute_input": "2023-10-25T14:15:48.252037Z",
          "iopub.status.idle": "2023-10-25T14:15:48.261991Z",
          "shell.execute_reply.started": "2023-10-25T14:15:48.251991Z",
          "shell.execute_reply": "2023-10-25T14:15:48.260709Z"
        },
        "trusted": true,
        "id": "Tvjf_JRC02xg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Identify and remove smart meter readings not exactly on the half-hour"
      ],
      "metadata": {
        "id": "e4kmR0_r02xg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# identify and remove records not exactly on the half-hour\n",
        "start_time = time.time()\n",
        "\n",
        "offRecs = d.query(\"tstp.dt.minute not in (0,30) or tstp.dt.second != 0\")\n",
        "# aggLoad[\"DateTime\"].dt.hour > 30\n",
        "print('\\nRecords not exactly on the half-hour:\\n ', offRecs)\n",
        "print(offRecs.info())\n",
        "\n",
        "# delete records not exactly on the half-hour\n",
        "d.drop(offRecs.index, inplace=True)\n",
        "\n",
        "print('%s seconds' % (time.time() - start_time))\n",
        "\n",
        "offRecs = d.query(\"tstp.dt.minute not in (0,30) or tstp.dt.second != 0\")\n",
        "print('\\nRecords not exactly on the half-hour:\\n ', offRecs)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:15:48.26353Z",
          "iopub.execute_input": "2023-10-25T14:15:48.264542Z",
          "iopub.status.idle": "2023-10-25T14:17:20.09978Z",
          "shell.execute_reply.started": "2023-10-25T14:15:48.264494Z",
          "shell.execute_reply": "2023-10-25T14:17:20.097907Z"
        },
        "trusted": true,
        "id": "YB94Habd02xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d.info()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:17:20.101786Z",
          "iopub.execute_input": "2023-10-25T14:17:20.10222Z",
          "iopub.status.idle": "2023-10-25T14:17:20.117353Z",
          "shell.execute_reply.started": "2023-10-25T14:17:20.10218Z",
          "shell.execute_reply": "2023-10-25T14:17:20.115963Z"
        },
        "trusted": true,
        "id": "GGh1X5By02xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check what is gobbling RAM\n",
        "for name, size in sorted(((name, sys.getsizeof(value)) for name, value in list(\n",
        "                          locals().items())), key= lambda x: -x[1])[:10]:\n",
        "    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:17:20.119242Z",
          "iopub.execute_input": "2023-10-25T14:17:20.121126Z",
          "iopub.status.idle": "2023-10-25T14:18:18.572757Z",
          "shell.execute_reply.started": "2023-10-25T14:17:20.121065Z",
          "shell.execute_reply": "2023-10-25T14:18:18.571186Z"
        },
        "trusted": true,
        "id": "1k3JYcq902xt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fill gaps in the smart meter data\n",
        "\n",
        "Our heatmap above shows lots of gaps (small white vertical lines), and we'll fill those gaps using interpolation"
      ],
      "metadata": {
        "id": "5k9tNQCp02xt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First step of filling these gaps is to create NaN records where records are missing\n",
        "\n",
        "Then we can fill these gaps with interpolation"
      ],
      "metadata": {
        "id": "V_lCEiA102xt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First step of interpolation is to create NaN records where records are missing\n",
        "# about 2 minutes\n",
        "d.sort_values(by=['tstp'], inplace=True)\n",
        "d.set_index('tstp', inplace=True)\n",
        "d.index.rename('tstp', inplace=True)\n",
        "\n",
        "start_time = time.time()\n",
        "# resample to create NaN records where records are missing\n",
        "d = d.groupby('LCLid')\\\n",
        "                .resample('30Min')\\\n",
        "                .mean()\n",
        "\n",
        "# fill the gaps with interpolation\n",
        "d['kWhPerHalfHour'] = d['kWhPerHalfHour'].interpolate(limit=2, limit_area='inside')\n",
        "d.reset_index(inplace=True)\n",
        "\n",
        "print('%s seconds' % (time.time() - start_time))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:18:18.574997Z",
          "iopub.execute_input": "2023-10-25T14:18:18.575514Z",
          "iopub.status.idle": "2023-10-25T14:22:33.01063Z",
          "shell.execute_reply.started": "2023-10-25T14:18:18.57547Z",
          "shell.execute_reply": "2023-10-25T14:22:33.0088Z"
        },
        "trusted": true,
        "id": "YHqkO8E_02xt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check the meter data heatmap to see if gaps have been filled"
      ],
      "metadata": {
        "id": "wmOQMqxq02xt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize after interpolating missing values\n",
        "d.info()\n",
        "sample = d[d['LCLid'].isin(sampleMeters)]\n",
        "pivot_table = pd.pivot_table(sample, columns='tstp', index='LCLid', values='kWhPerHalfHour')\n",
        "plt.subplots(figsize=(20,5))\n",
        "sns.heatmap(pivot_table, xticklabels=48*30) # one xtick label every month\n",
        "plt.title('Meter Data Heatmap', size=15)\n",
        "plt.savefig('meter data heatmap gaps filled.png', format='png')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:22:33.013268Z",
          "iopub.execute_input": "2023-10-25T14:22:33.013754Z",
          "iopub.status.idle": "2023-10-25T14:22:58.641584Z",
          "shell.execute_reply.started": "2023-10-25T14:22:33.013715Z",
          "shell.execute_reply": "2023-10-25T14:22:58.63964Z"
        },
        "trusted": true,
        "id": "NLifOp7l02xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize zeros in the dataset using heatmap\n",
        "\n",
        "I'm always curious to understand zeros in a dataset, and whether they are legitimate zero values, or indicate a data quality problem."
      ],
      "metadata": {
        "id": "SiQGcQj802xu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize zeros in the dataset\n",
        "start_time = time.time()\n",
        "sample = d[d['LCLid'].isin(sampleMeters)]\n",
        "sample['ZerokWhPerHalfHour'] = sample['kWhPerHalfHour'] == 0\n",
        "pivot_table = pd.pivot_table(sample, columns='tstp', index='LCLid', values='ZerokWhPerHalfHour')\n",
        "print('%s seconds' % (time.time() - start_time))\n",
        "plt.subplots(figsize=(20,5))\n",
        "sns.heatmap(pivot_table, xticklabels=48*30)\n",
        "plt.title('Meter data heatmap zero reads', size=15)\n",
        "plt.savefig('meter data heatmap zeros.png', format='png')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:22:58.643447Z",
          "iopub.execute_input": "2023-10-25T14:22:58.643902Z",
          "iopub.status.idle": "2023-10-25T14:23:23.779041Z",
          "shell.execute_reply.started": "2023-10-25T14:22:58.643857Z",
          "shell.execute_reply": "2023-10-25T14:23:23.77779Z"
        },
        "trusted": true,
        "id": "oP5YuwoT02xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# take a snapshot of data\n",
        "# takes about 11 minutes\n",
        "start_time = time.time()\n",
        "d.to_csv('/kaggle/working/MeterDataFinal.csv',index=False)\n",
        "print('%s seconds' % (time.time() - start_time))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:23:23.781134Z",
          "iopub.execute_input": "2023-10-25T14:23:23.781535Z",
          "iopub.status.idle": "2023-10-25T14:42:32.796698Z",
          "shell.execute_reply.started": "2023-10-25T14:23:23.781498Z",
          "shell.execute_reply": "2023-10-25T14:42:32.794534Z"
        },
        "trusted": true,
        "id": "Balz6q5Z02xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gather the meters from the sample that have zero reads and count how many zero reads each has\n",
        "sampleMetersWithZeroReads = sample[sample['kWhPerHalfHour'] == 0].groupby('LCLid').agg('count')\n",
        "sampleMetersWithZeroReads"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:42:32.799422Z",
          "iopub.execute_input": "2023-10-25T14:42:32.799833Z",
          "iopub.status.idle": "2023-10-25T14:42:32.842267Z",
          "shell.execute_reply.started": "2023-10-25T14:42:32.7998Z",
          "shell.execute_reply": "2023-10-25T14:42:32.841255Z"
        },
        "trusted": true,
        "id": "2RFRdikl02xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# investigate the meters with zero reads\n",
        "MAC002050 = sample.query(\"LCLid == 'MAC002050'\")\n",
        "print(MAC002050)\n",
        "fig, ax = plt.subplots(4,figsize=(20,9))\n",
        "\n",
        "# plot whole ~2 years\n",
        "ax[0].plot(MAC002050.tstp, MAC002050.kWhPerHalfHour)\n",
        "ax[0].plot(MAC002050.tstp, MAC002050.ZerokWhPerHalfHour)\n",
        "ax[0].set(ylabel='kWh per half-hour',\n",
        "       title='Load from one Household MAC002050 with lots of zero values')\n",
        "plt.tick_params(rotation=45)\n",
        "ax[0].grid()\n",
        "\n",
        "# zoom in\n",
        "ax[1].plot(MAC002050.tstp[11000:15000], MAC002050.kWhPerHalfHour[11000:15000])\n",
        "ax[1].plot(MAC002050.tstp[11000:15000], MAC002050.ZerokWhPerHalfHour[11000:15000])\n",
        "ax[1].set(xlabel='time (s)', ylabel='kWh per half-hour')\n",
        "plt.tick_params(rotation=45)\n",
        "ax[1].grid()\n",
        "\n",
        "# zoom in more...\n",
        "ax[2].plot(MAC002050.tstp[13000:13500], MAC002050.kWhPerHalfHour[13000:13500])\n",
        "ax[2].plot(MAC002050.tstp[13000:13500], MAC002050.ZerokWhPerHalfHour[13000:13500])\n",
        "ax[2].set(xlabel='time (s)', ylabel='kWh per half-hour')\n",
        "plt.tick_params(rotation=45)\n",
        "ax[2].grid()\n",
        "\n",
        "# zoom in to a different part of the series...\n",
        "ax[3].plot(MAC002050.tstp[25000:25500], MAC002050.kWhPerHalfHour[25000:25500])\n",
        "ax[3].plot(MAC002050.tstp[25000:25500], MAC002050.ZerokWhPerHalfHour[25000:25500])\n",
        "ax[3].set(xlabel='time (s)', ylabel='kWh per half-hour')\n",
        "plt.tick_params(rotation=45)\n",
        "ax[3].grid()\n",
        "\n",
        "fig.savefig(\"MAC002050.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:42:32.844055Z",
          "iopub.execute_input": "2023-10-25T14:42:32.8457Z",
          "iopub.status.idle": "2023-10-25T14:42:34.611994Z",
          "shell.execute_reply.started": "2023-10-25T14:42:32.845601Z",
          "shell.execute_reply": "2023-10-25T14:42:34.610352Z"
        },
        "trusted": true,
        "id": "xuBjijJh02xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation: The zeros for MAC002050 seem legit - leaving them in"
      ],
      "metadata": {
        "id": "0Y_hPGoS02xv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# investigate the meters with zero reads\n",
        "MAC001558 = sample.query(\"LCLid == 'MAC001558'\")\n",
        "fig, ax = plt.subplots(4,figsize=(20,9))\n",
        "\n",
        "# plot whole ~2 years\n",
        "ax[0].plot(MAC001558.tstp, MAC001558.kWhPerHalfHour)\n",
        "ax[0].plot(MAC001558.tstp, MAC001558.ZerokWhPerHalfHour)\n",
        "ax[0].set(ylabel='kWh per half-hour',\n",
        "       title='Load from one Household MAC001558 with lots of zero values')\n",
        "plt.tick_params(rotation=45)\n",
        "ax[0].grid()\n",
        "\n",
        "# zoom in\n",
        "ax[1].plot(MAC001558.tstp[17000:21000], MAC001558.kWhPerHalfHour[17000:21000])\n",
        "ax[1].plot(MAC001558.tstp[17000:21000], MAC001558.ZerokWhPerHalfHour[17000:21000])\n",
        "ax[1].set(xlabel='time (s)', ylabel='kWh per half-hour')\n",
        "plt.tick_params(rotation=45)\n",
        "ax[1].grid()\n",
        "\n",
        "# zoom in more...\n",
        "ax[2].plot(MAC001558.tstp[19300:19800], MAC001558.kWhPerHalfHour[19300:19800])\n",
        "ax[2].plot(MAC001558.tstp[19300:19800], MAC001558.ZerokWhPerHalfHour[19300:19800])\n",
        "ax[2].set(xlabel='time (s)', ylabel='kWh per half-hour')\n",
        "plt.tick_params(rotation=45)\n",
        "ax[2].grid()\n",
        "\n",
        "# zoom in to a different part of the series...\n",
        "ax[3].plot(MAC001558.tstp[25000:25500], MAC001558.kWhPerHalfHour[25000:25500])\n",
        "ax[3].plot(MAC001558.tstp[25000:25500], MAC001558.ZerokWhPerHalfHour[25000:25500])\n",
        "ax[3].set(xlabel='time (s)', ylabel='kWh per half-hour')\n",
        "plt.tick_params(rotation=45)\n",
        "ax[3].grid()\n",
        "\n",
        "fig.savefig(\"MAC001558.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:42:34.614054Z",
          "iopub.execute_input": "2023-10-25T14:42:34.614503Z",
          "iopub.status.idle": "2023-10-25T14:42:36.428564Z",
          "shell.execute_reply.started": "2023-10-25T14:42:34.614465Z",
          "shell.execute_reply": "2023-10-25T14:42:36.42688Z"
        },
        "trusted": true,
        "id": "0Zp0WIT802xw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation: The zeros for MAC001558 seem legit - leaving them in"
      ],
      "metadata": {
        "id": "lj_ZPH2c02xw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# explore some basic stats for each house\n",
        "print(d.groupby('LCLid').max().sort_values('tstp'))\n",
        "print(d.groupby('LCLid').min().sort_values('tstp'))\n",
        "print(d.groupby('LCLid').count().sort_values('tstp'))\n",
        "\n",
        "print(d.groupby('LCLid').agg(['min', 'max', 'count']))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:42:36.430957Z",
          "iopub.execute_input": "2023-10-25T14:42:36.431509Z",
          "iopub.status.idle": "2023-10-25T14:44:07.888125Z",
          "shell.execute_reply.started": "2023-10-25T14:42:36.43146Z",
          "shell.execute_reply": "2023-10-25T14:44:07.88705Z"
        },
        "trusted": true,
        "id": "DMoFl8VB02xw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set index for the sample\n",
        "sample.set_index('tstp')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:44:07.88957Z",
          "iopub.execute_input": "2023-10-25T14:44:07.89057Z",
          "iopub.status.idle": "2023-10-25T14:44:07.940073Z",
          "shell.execute_reply.started": "2023-10-25T14:44:07.890529Z",
          "shell.execute_reply": "2023-10-25T14:44:07.939021Z"
        },
        "trusted": true,
        "id": "vt2MUQQo02xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA: Visualize daily average load for each meter and all meters..."
      ],
      "metadata": {
        "id": "wo9Mx4jI02xy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate average daily load profile for all meters...\n",
        "# about 1.5 minutes\n",
        "\n",
        "start_time = time.time()\n",
        "avgLoadProfile = pd.DataFrame(d.groupby([d['tstp'].dt.hour, d['tstp'].dt.minute]).kWhPerHalfHour.mean())\n",
        "avgLoadProfile = avgLoadProfile.reset_index(names=['hour', 'minute'])\n",
        "avgLoadProfile['labels'] = pd.to_datetime(avgLoadProfile['hour'].astype(str) + ':' + avgLoadProfile['minute'].astype(str), format='%H:%M').dt.time\n",
        "print('%s seconds' % (time.time() - start_time))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,7))\n",
        "\n",
        "ax.set_xticks(avgLoadProfile.index, avgLoadProfile.labels)\n",
        "\n",
        "ax.set(xlabel='time (HH:MI)', ylabel='kWh per half-hour',\n",
        "       title='Average Household 24 hour load profile')\n",
        "\n",
        "# calculate average daily load for each meter...\n",
        "start_time = time.time()\n",
        "avgLoadProfileEachMeter = pd.DataFrame(d.groupby(['LCLid', d['tstp'].dt.hour, d['tstp'].dt.minute]).agg({'kWhPerHalfHour': 'mean'}))\n",
        "avgLoadProfileEachMeter = avgLoadProfileEachMeter.reset_index(names=['LCLid', 'hour', 'minute'])\n",
        "print('%s seconds' % (time.time() - start_time))\n",
        "# print(avgLoadProfileEachMeter.info())\n",
        "# print(avgLoadProfileEachMeter)\n",
        "\n",
        "# plot every sample meter\n",
        "for meter in sampleMeters:\n",
        "    # print(meter)\n",
        "    ax.plot(avgLoadProfileEachMeter.loc[avgLoadProfileEachMeter['LCLid'] == meter].index % 48,\n",
        "            avgLoadProfileEachMeter.loc[avgLoadProfileEachMeter['LCLid'] == meter].kWhPerHalfHour,\n",
        "           color='grey')\n",
        "\n",
        "# plot the average\n",
        "ax.plot(avgLoadProfile.index, avgLoadProfile.kWhPerHalfHour, linewidth=5)\n",
        "\n",
        "plt.tick_params(rotation=45)\n",
        "ax.grid()\n",
        "\n",
        "fig.savefig(\"Avg 24hr Load Profile every meter.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:44:07.941488Z",
          "iopub.execute_input": "2023-10-25T14:44:07.942721Z",
          "iopub.status.idle": "2023-10-25T14:46:41.710568Z",
          "shell.execute_reply.started": "2023-10-25T14:44:07.942638Z",
          "shell.execute_reply": "2023-10-25T14:46:41.708843Z"
        },
        "trusted": true,
        "id": "KUlbNXMv02xy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create aggregate features: aggregate load (our target) and count of meters"
      ],
      "metadata": {
        "id": "ezQlUGzI02xy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the sum of all loads and count of smart meters for each timestamp\n",
        "start_time = time.time()\n",
        "aggLoad = pd.DataFrame(d.groupby('tstp')['kWhPerHalfHour'].agg({'sum', 'count'}))\n",
        "aggLoad.reset_index(inplace=True)\n",
        "aggLoad.columns = ['tstp', 'numMeters', 'AggregateLoad']\n",
        "print('%s seconds' % (time.time() - start_time))\n",
        "\n",
        "print(aggLoad)\n",
        "print(aggLoad.describe())\n",
        "print(aggLoad.info())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:52:26.420884Z",
          "iopub.execute_input": "2023-10-25T14:52:26.421486Z",
          "iopub.status.idle": "2023-10-25T14:52:35.570547Z",
          "shell.execute_reply.started": "2023-10-25T14:52:26.421448Z",
          "shell.execute_reply": "2023-10-25T14:52:35.568995Z"
        },
        "trusted": true,
        "id": "ZdLQJodJ02xy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aggLoad.sort_values(by=['tstp'], inplace=True)\n",
        "aggLoad.set_index('tstp', inplace=True)\n",
        "aggLoad.index.rename('DateTimeIndex', inplace=True)\n",
        "aggLoad.info()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:52:48.188845Z",
          "iopub.execute_input": "2023-10-25T14:52:48.189284Z",
          "iopub.status.idle": "2023-10-25T14:52:48.211004Z",
          "shell.execute_reply.started": "2023-10-25T14:52:48.189251Z",
          "shell.execute_reply": "2023-10-25T14:52:48.209394Z"
        },
        "trusted": true,
        "id": "CNu_b--i02xz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aggLoad['DateTime'] = aggLoad.index\n",
        "aggLoad.info()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:52:48.213643Z",
          "iopub.execute_input": "2023-10-25T14:52:48.214104Z",
          "iopub.status.idle": "2023-10-25T14:52:48.232396Z",
          "shell.execute_reply.started": "2023-10-25T14:52:48.214068Z",
          "shell.execute_reply": "2023-10-25T14:52:48.231007Z"
        },
        "trusted": true,
        "id": "zZ_w0y5J02xz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# identify records with zero load\n",
        "# start with the aggregated records with zero load\n",
        "AggZeros = aggLoad.query(\"AggregateLoad == 0\")\n",
        "AggZeros"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:52:48.234085Z",
          "iopub.execute_input": "2023-10-25T14:52:48.234517Z",
          "iopub.status.idle": "2023-10-25T14:52:48.252107Z",
          "shell.execute_reply.started": "2023-10-25T14:52:48.23448Z",
          "shell.execute_reply": "2023-10-25T14:52:48.250754Z"
        },
        "trusted": true,
        "id": "4c6z_W6402xz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inspect and fix records not exactly on the half-hour\n",
        "offRecs = aggLoad.query(\"DateTime.dt.minute not in (0,30) or DateTime.dt.second != 0\")\n",
        "print('Records not exactly on the half-hour: ', offRecs)\n",
        "print(offRecs.info())\n",
        "\n",
        "# delete records not exactly on the half-hour\n",
        "aggLoad = aggLoad.drop(offRecs.index)\n",
        "\n",
        "offRecs = aggLoad.query(\"DateTime.dt.minute not in (0,30) or DateTime.dt.second != 0\")\n",
        "print('Records not exactly on the half-hour: ', offRecs)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:52:48.256334Z",
          "iopub.execute_input": "2023-10-25T14:52:48.256923Z",
          "iopub.status.idle": "2023-10-25T14:52:48.316753Z",
          "shell.execute_reply.started": "2023-10-25T14:52:48.256877Z",
          "shell.execute_reply": "2023-10-25T14:52:48.315431Z"
        },
        "trusted": true,
        "id": "XqswG_7W02x0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the regularity of the observations (time between observations)\n",
        "# print(pd.infer_freq(train_data.DateTime))\n",
        "aggLoad.index.to_series().diff().value_counts()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:52:48.318126Z",
          "iopub.execute_input": "2023-10-25T14:52:48.318621Z",
          "iopub.status.idle": "2023-10-25T14:52:48.331515Z",
          "shell.execute_reply.started": "2023-10-25T14:52:48.318567Z",
          "shell.execute_reply": "2023-10-25T14:52:48.330279Z"
        },
        "trusted": true,
        "id": "YVeXaWYd02x0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate moving average and stddev for the aggregated load across all meters\n",
        "window_size = int(len(aggLoad.AggregateLoad) / 10)\n",
        "print(window_size)\n",
        "\n",
        "aggLoadMovingStdev = aggLoad.AggregateLoad.rolling(window_size).std()\n",
        "aggLoadMovingStdev.columns = ['MovingStdev']\n",
        "\n",
        "aggLoadMovingAvg = aggLoad.AggregateLoad.rolling(window_size).mean()\n",
        "aggLoadMovingAvg.columns = ['MovingAvg']\n",
        "\n",
        "print('aggLoadMovingStdev:\\n', aggLoadMovingStdev)\n",
        "print(aggLoadMovingStdev.info())\n",
        "print('aggLoadMovingAvg:\\n', aggLoadMovingAvg)\n",
        "print(aggLoadMovingAvg.info())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:52:48.333258Z",
          "iopub.execute_input": "2023-10-25T14:52:48.333781Z",
          "iopub.status.idle": "2023-10-25T14:52:48.363102Z",
          "shell.execute_reply.started": "2023-10-25T14:52:48.333735Z",
          "shell.execute_reply": "2023-10-25T14:52:48.361728Z"
        },
        "trusted": true,
        "id": "dthQDmZO02x0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize aggregate load, moving average, moving standard deviation\n",
        "# print(aggLoad)\n",
        "fig, ax = plt.subplots(figsize=(20,7))\n",
        "ax.plot(aggLoad.DateTime, aggLoad.AggregateLoad, label=\"Aggregate Load\")\n",
        "ax.plot(aggLoad.DateTime, aggLoadMovingAvg, linewidth=3, label=\"Moving Average\")\n",
        "ax.plot(aggLoad.DateTime, aggLoadMovingStdev, linewidth=3, label=\"Moving Stdev\")\n",
        "\n",
        "ax.set(xlabel='time', ylabel='kWh per half-hour',\n",
        "       title='Aggregate Household load 2012-2014')\n",
        "plt.tick_params(rotation=45)\n",
        "ax.grid()\n",
        "\n",
        "plt.legend(fontsize=15)\n",
        "fig.savefig(\"Aggregate Household load 2012-2014.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:05:44.577038Z",
          "iopub.execute_input": "2023-10-25T15:05:44.57828Z",
          "iopub.status.idle": "2023-10-25T15:05:45.638817Z",
          "shell.execute_reply.started": "2023-10-25T15:05:44.578227Z",
          "shell.execute_reply": "2023-10-25T15:05:45.637475Z"
        },
        "trusted": true,
        "id": "JMHmQDOw02x0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show curve of number of meters contributing to the aggregate load\n",
        "# This shows correlation of increased load with meters being added to the program during the recruitment period\n",
        "# print(aggLoad)\n",
        "fig, ax = plt.subplots(figsize=(20,7))\n",
        "ax.plot(aggLoad.DateTime, aggLoad.numMeters, linewidth=3, label=\"Number of Meters\")\n",
        "\n",
        "ax.set(xlabel='time', ylabel='Number of Meters',\n",
        "       title='Meter growth 2012-2014')\n",
        "plt.tick_params(rotation=45)\n",
        "ax.grid()\n",
        "\n",
        "fig.savefig(\"Meter growth 2012-2014.png\")\n",
        "plt.legend(fontsize=15)\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:06:43.262036Z",
          "iopub.execute_input": "2023-10-25T15:06:43.262595Z",
          "iopub.status.idle": "2023-10-25T15:06:43.968526Z",
          "shell.execute_reply.started": "2023-10-25T15:06:43.262556Z",
          "shell.execute_reply": "2023-10-25T15:06:43.967042Z"
        },
        "trusted": true,
        "id": "Wt_ibVk202x0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explore our aggregate load curve at various scales\n",
        "\n",
        "Zoom in gradually to a single day"
      ],
      "metadata": {
        "id": "hdWFZiFF02x1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregate Household load June-August\n",
        "fig, ax = plt.subplots(figsize=(20,7))\n",
        "ax.plot(aggLoad.DateTime[10000:15000], aggLoad.AggregateLoad[10000:15000])\n",
        "\n",
        "ax.set(xlabel='time (s)', ylabel='kWh per half-hour',\n",
        "       title='Aggregate Household load June-August 2012')\n",
        "plt.tick_params(rotation=45)\n",
        "ax.grid()\n",
        "\n",
        "fig.savefig(\"Aggregate Household load June-August 2012.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:52:50.559556Z",
          "iopub.execute_input": "2023-10-25T14:52:50.560028Z",
          "iopub.status.idle": "2023-10-25T14:52:51.424584Z",
          "shell.execute_reply.started": "2023-10-25T14:52:50.559972Z",
          "shell.execute_reply": "2023-10-25T14:52:51.423066Z"
        },
        "trusted": true,
        "id": "xSO-1C6502x1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregate Household load one month\n",
        "fig, ax = plt.subplots(figsize=(20,7))\n",
        "ax.plot(aggLoad.DateTime[12000:13000], aggLoad.AggregateLoad[12000:13000])\n",
        "\n",
        "ax.set(xlabel='time (s)', ylabel='kWh per half-hour',\n",
        "       title='Aggregate Household load one month')\n",
        "plt.tick_params(rotation=45)\n",
        "ax.grid()\n",
        "\n",
        "fig.savefig(\"Aggregate Household load one month.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:52:51.4262Z",
          "iopub.execute_input": "2023-10-25T14:52:51.42656Z",
          "iopub.status.idle": "2023-10-25T14:52:52.111303Z",
          "shell.execute_reply.started": "2023-10-25T14:52:51.426529Z",
          "shell.execute_reply": "2023-10-25T14:52:52.109664Z"
        },
        "trusted": true,
        "id": "6Dw5dRYZ02x1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregate Household load ~two days\n",
        "fig, ax = plt.subplots(figsize=(20,7))\n",
        "ax.plot(aggLoad.DateTime[12500:12600], aggLoad.AggregateLoad[12500:12600])\n",
        "\n",
        "ax.set(xlabel='time (s)', ylabel='kWh per half-hour',\n",
        "       title='Aggregate Household load ~two days')\n",
        "plt.tick_params(rotation=45)\n",
        "ax.grid()\n",
        "\n",
        "fig.savefig(\"Aggregate Household load two days.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:52:52.11285Z",
          "iopub.execute_input": "2023-10-25T14:52:52.113235Z",
          "iopub.status.idle": "2023-10-25T14:52:52.789697Z",
          "shell.execute_reply.started": "2023-10-25T14:52:52.113185Z",
          "shell.execute_reply": "2023-10-25T14:52:52.788175Z"
        },
        "trusted": true,
        "id": "4GlJ3bHf02x1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregate Household load (one day)\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(aggLoad.DateTime[12500:12550], aggLoad.AggregateLoad[12500:12550])\n",
        "\n",
        "ax.set(xlabel='time (s)', ylabel='kWh per half-hour',\n",
        "       title='Aggregate Household load (one day)')\n",
        "plt.tick_params(rotation=45)\n",
        "ax.grid()\n",
        "\n",
        "fig.savefig(\"Aggregate Household load (one day).png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:52:52.791524Z",
          "iopub.execute_input": "2023-10-25T14:52:52.792197Z",
          "iopub.status.idle": "2023-10-25T14:52:53.27604Z",
          "shell.execute_reply.started": "2023-10-25T14:52:52.792161Z",
          "shell.execute_reply": "2023-10-25T14:52:53.27508Z"
        },
        "trusted": true,
        "id": "gwaW-qez02x2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aggLoad.to_csv('/kaggle/working/aggLoadDataFinal.csv',index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:52:53.277258Z",
          "iopub.execute_input": "2023-10-25T14:52:53.278297Z",
          "iopub.status.idle": "2023-10-25T14:52:53.596651Z",
          "shell.execute_reply.started": "2023-10-25T14:52:53.278259Z",
          "shell.execute_reply": "2023-10-25T14:52:53.59512Z"
        },
        "trusted": true,
        "id": "QOEDwZ6Q02x2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aggLoad = pd.read_csv('/kaggle/working/aggLoadDataFinal.csv', parse_dates=[\"DateTime\"])\n",
        "aggLoad"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:52:53.598261Z",
          "iopub.execute_input": "2023-10-25T14:52:53.598629Z",
          "iopub.status.idle": "2023-10-25T14:52:53.670704Z",
          "shell.execute_reply.started": "2023-10-25T14:52:53.5986Z",
          "shell.execute_reply": "2023-10-25T14:52:53.669471Z"
        },
        "trusted": true,
        "id": "F8g4GUxK02x2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aggLoad.iloc[35299]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:52:53.672334Z",
          "iopub.execute_input": "2023-10-25T14:52:53.672845Z",
          "iopub.status.idle": "2023-10-25T14:52:53.683445Z",
          "shell.execute_reply.started": "2023-10-25T14:52:53.672811Z",
          "shell.execute_reply": "2023-10-25T14:52:53.681927Z"
        },
        "trusted": true,
        "id": "TuiPVITK02x2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Join load data and weather data\n",
        "mergeData = pd.merge(aggLoad, weatherUpsample, on='DateTime', copy=False)\n",
        "print(mergeData.info())\n",
        "mergeData"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:52:53.685728Z",
          "iopub.execute_input": "2023-10-25T14:52:53.686149Z",
          "iopub.status.idle": "2023-10-25T14:52:53.729779Z",
          "shell.execute_reply.started": "2023-10-25T14:52:53.686116Z",
          "shell.execute_reply": "2023-10-25T14:52:53.728939Z"
        },
        "trusted": true,
        "id": "p20n3ASE02x2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot autocorrelation of aggregate load (target)\n",
        "\n",
        "...to investigate cyclical properties"
      ],
      "metadata": {
        "id": "CN98eFXA02x3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.graphics.tsaplots import plot_acf\n",
        "\n",
        "# Extract the AggregateLoad feature\n",
        "aggregate_load = mergeData['AggregateLoad']\n",
        "\n",
        "# Plot the autocorrelation plot\n",
        "plot_acf(aggregate_load, lags=100)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:52:53.731192Z",
          "iopub.execute_input": "2023-10-25T14:52:53.731776Z",
          "iopub.status.idle": "2023-10-25T14:52:54.623643Z",
          "shell.execute_reply.started": "2023-10-25T14:52:53.731742Z",
          "shell.execute_reply": "2023-10-25T14:52:54.622292Z"
        },
        "trusted": true,
        "id": "ta0al5rv02x3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature engineering"
      ],
      "metadata": {
        "id": "hGLpPXSP02x3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cyclical features"
      ],
      "metadata": {
        "id": "jyUxEzB802x3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add features useful for time series\n",
        "print(mergeData.info())\n",
        "# Cyclical features\n",
        "# week of year\n",
        "weekOfYear = mergeData.DateTime.dt.weekofyear\n",
        "mergeData[\"weekOfYear_sin\"] = np.sin(weekOfYear*(2.*np.pi/52))\n",
        "mergeData[\"weekOfYear_cos\"] = np.cos(weekOfYear*(2.*np.pi/52))\n",
        "# day of week\n",
        "dayOfWeek = mergeData.DateTime.dt.dayofweek\n",
        "mergeData[\"dayOfWeek_sin\"] = np.sin(dayOfWeek*(2.*np.pi/7))\n",
        "mergeData[\"dayOfWeek_cos\"] = np.cos(dayOfWeek*(2.*np.pi/7))\n",
        "# day of year\n",
        "# aggLoad[\"dayOfYear\"] = aggLoad.DateTime.dt.dayofyear\n",
        "# minute of the day\n",
        "minuteOfDay = (mergeData.DateTime.dt.hour * 60) + mergeData.DateTime.dt.minute\n",
        "mergeData[\"minuteOfDay_sin\"] = np.sin(minuteOfDay*(2.*np.pi/48))\n",
        "mergeData[\"minuteOfDay_cos\"] = np.cos(minuteOfDay*(2.*np.pi/48))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:52:54.625824Z",
          "iopub.execute_input": "2023-10-25T14:52:54.627217Z",
          "iopub.status.idle": "2023-10-25T14:52:54.707449Z",
          "shell.execute_reply.started": "2023-10-25T14:52:54.627148Z",
          "shell.execute_reply": "2023-10-25T14:52:54.705865Z"
        },
        "trusted": true,
        "id": "oKioDFtQ02x3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decomposition features"
      ],
      "metadata": {
        "id": "JbqJTMdF02x4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decomp_df = pd.DataFrame(mergeData.copy())\n",
        "decomp_df = decomp_df.set_index(pd.DatetimeIndex(decomp_df['DateTime']))\n",
        "decomp_df.index=decomp_df.DateTime\n",
        "decomp_df = decomp_df.AggregateLoad\n",
        "print(decomp_df.describe())\n",
        "print(decomp_df.info)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:52:54.709227Z",
          "iopub.execute_input": "2023-10-25T14:52:54.709619Z",
          "iopub.status.idle": "2023-10-25T14:52:54.73391Z",
          "shell.execute_reply.started": "2023-10-25T14:52:54.709586Z",
          "shell.execute_reply": "2023-10-25T14:52:54.732397Z"
        },
        "trusted": true,
        "id": "1xQmgQf802x4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Annual decomposition\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "yearly_seasonal_decomp = seasonal_decompose(mergeData['AggregateLoad'], period=17532)\n",
        "mergeData['yearlySeasonal']=yearly_seasonal_decomp.seasonal\n",
        "yearly_seasonal_decomp.plot()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:52:54.735407Z",
          "iopub.execute_input": "2023-10-25T14:52:54.735796Z",
          "iopub.status.idle": "2023-10-25T14:52:57.912206Z",
          "shell.execute_reply.started": "2023-10-25T14:52:54.735763Z",
          "shell.execute_reply": "2023-10-25T14:52:57.910758Z"
        },
        "trusted": true,
        "id": "IphoO2BT02x4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# daily decomposition\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "daily_seasonal_decomp = seasonal_decompose(mergeData['AggregateLoad'], period=48)\n",
        "mergeData['dailyTrend']=daily_seasonal_decomp.trend\n",
        "mergeData['dailySeasonal']=daily_seasonal_decomp.seasonal\n",
        "mergeData['dailyResid']=daily_seasonal_decomp.resid\n",
        "daily_seasonal_decomp.plot();"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:52:57.914084Z",
          "iopub.execute_input": "2023-10-25T14:52:57.914863Z",
          "iopub.status.idle": "2023-10-25T14:52:59.316135Z",
          "shell.execute_reply.started": "2023-10-25T14:52:57.914822Z",
          "shell.execute_reply": "2023-10-25T14:52:59.314488Z"
        },
        "trusted": true,
        "id": "OmG7zaK402x4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# weekly decomposition\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "weekly_seasonal_decomp = seasonal_decompose(mergeData['AggregateLoad'], period=336)\n",
        "mergeData['weeklyTrend']=weekly_seasonal_decomp.trend\n",
        "mergeData['weeklySeasonal']=weekly_seasonal_decomp.seasonal\n",
        "mergeData['weeklyResid']=weekly_seasonal_decomp.resid\n",
        "weekly_seasonal_decomp.plot();"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:52:59.318267Z",
          "iopub.execute_input": "2023-10-25T14:52:59.318689Z",
          "iopub.status.idle": "2023-10-25T14:53:00.727263Z",
          "shell.execute_reply.started": "2023-10-25T14:52:59.31864Z",
          "shell.execute_reply": "2023-10-25T14:53:00.725775Z"
        },
        "trusted": true,
        "id": "Lx_Hdj-Z02x4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lag features"
      ],
      "metadata": {
        "id": "zmPEYoxe02x4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load 1 day lag\n",
        "oneDayPeriods = 48\n",
        "mergeData['AggregateLoad_1dayLag'] = mergeData['AggregateLoad'].shift(oneDayPeriods)\n",
        "# load 1 week lag\n",
        "oneWeekPeriods = oneDayPeriods * 7\n",
        "mergeData['AggregateLoad_1weekLag'] = mergeData['AggregateLoad'].shift(oneWeekPeriods)\n",
        "\n",
        "# load change from last half-hour to this half-hour\n",
        "mergeData['AggregateLoad_halfhourdiff'] = mergeData['AggregateLoad'] - mergeData['AggregateLoad'].shift(1)\n",
        "# load change from one week ago to this half-hour\n",
        "mergeData['AggregateLoad_weekdiff'] = mergeData['AggregateLoad'] - mergeData['AggregateLoad'].shift(oneWeekPeriods)\n",
        "\n",
        "print(mergeData.info())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:53:00.729472Z",
          "iopub.execute_input": "2023-10-25T14:53:00.730015Z",
          "iopub.status.idle": "2023-10-25T14:53:00.758565Z",
          "shell.execute_reply.started": "2023-10-25T14:53:00.729968Z",
          "shell.execute_reply": "2023-10-25T14:53:00.757057Z"
        },
        "trusted": true,
        "id": "6nsDaDzt02x5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop NaNs created by feature engineering\n",
        "mergeData.dropna(inplace=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:53:00.767738Z",
          "iopub.execute_input": "2023-10-25T14:53:00.768136Z",
          "iopub.status.idle": "2023-10-25T14:53:00.783741Z",
          "shell.execute_reply.started": "2023-10-25T14:53:00.768106Z",
          "shell.execute_reply": "2023-10-25T14:53:00.782363Z"
        },
        "trusted": true,
        "id": "Onsigbto02x5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# temperature change from last half-hour to this half-hour\n",
        "# eliminated due to permutation feature importance\n",
        "# weatherUpsample['temp_halfhourdiff'] = weatherUpsample['temperature'] - weatherUpsample['temperature'].shift(1)\n",
        "\n",
        "# max temp for the day\n",
        "mergeData['temp_daymax'] = mergeData.groupby(mergeData.DateTime.dt.date)['temperature'].transform('max')\n",
        "mergeData['temp_daymin'] = mergeData.groupby(weatherUpsample.DateTime.dt.date)['temperature'].transform('min')\n",
        "print(mergeData['temp_daymax'])\n",
        "print(mergeData['temp_daymin'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:53:00.786043Z",
          "iopub.execute_input": "2023-10-25T14:53:00.786592Z",
          "iopub.status.idle": "2023-10-25T14:53:00.879167Z",
          "shell.execute_reply.started": "2023-10-25T14:53:00.786543Z",
          "shell.execute_reply": "2023-10-25T14:53:00.877692Z"
        },
        "trusted": true,
        "id": "wz00Q9FA02x5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# Find the earliest date when there is the maximum number of meters contributing to the aggregate load\n",
        "# will disreard all data beofre this point\n",
        "maxMeters = aggLoad['numMeters'].max()\n",
        "print(maxMeters)\n",
        "startDateTime = aggLoad[aggLoad['numMeters']==maxMeters].DateTime.min()\n",
        "print(startDateTime)\n",
        "startDate = startDateTime.date()\n",
        "print(startDate)\n",
        "\"\"\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:53:00.880725Z",
          "iopub.execute_input": "2023-10-25T14:53:00.881086Z",
          "iopub.status.idle": "2023-10-25T14:53:00.888042Z",
          "shell.execute_reply.started": "2023-10-25T14:53:00.881055Z",
          "shell.execute_reply": "2023-10-25T14:53:00.887171Z"
        },
        "trusted": true,
        "id": "m12dcaGX02x5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move first column to the Last\n",
        "# df = pd.DataFrame(mergeData)\n",
        "df = mergeData\n",
        "temp_cols=df.columns.tolist()\n",
        "new_cols=temp_cols[1:] + temp_cols[0:1]\n",
        "mergeData=df[new_cols]\n",
        "print(mergeData)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:53:00.888982Z",
          "iopub.execute_input": "2023-10-25T14:53:00.889281Z",
          "iopub.status.idle": "2023-10-25T14:53:00.927335Z",
          "shell.execute_reply.started": "2023-10-25T14:53:00.889254Z",
          "shell.execute_reply": "2023-10-25T14:53:00.925746Z"
        },
        "trusted": true,
        "id": "mOpQ-0S702x5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas_profiling import ProfileReport\n",
        "\n",
        "profile = ProfileReport(mergeData, tsmode=True, sortby=\"DateTime\")\n",
        "profile.to_file('mergeData profile_report.html')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:53:00.929269Z",
          "iopub.execute_input": "2023-10-25T14:53:00.93018Z",
          "iopub.status.idle": "2023-10-25T14:59:41.60458Z",
          "shell.execute_reply.started": "2023-10-25T14:53:00.930119Z",
          "shell.execute_reply": "2023-10-25T14:59:41.603077Z"
        },
        "trusted": true,
        "id": "0k5G8C6L02x6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the dateTime feature from the dataset (we've extracted to features we need from it)\n",
        "print(mergeData)\n",
        "mergeData.drop(columns=['DateTime'], inplace=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:59:41.606814Z",
          "iopub.execute_input": "2023-10-25T14:59:41.607418Z",
          "iopub.status.idle": "2023-10-25T14:59:41.645655Z",
          "shell.execute_reply.started": "2023-10-25T14:59:41.607363Z",
          "shell.execute_reply": "2023-10-25T14:59:41.644088Z"
        },
        "trusted": true,
        "id": "_na6gFuV02x6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mergeData.to_csv('/kaggle/working/mergeDataFeatureCandidates.csv',index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:59:41.648421Z",
          "iopub.execute_input": "2023-10-25T14:59:41.649476Z",
          "iopub.status.idle": "2023-10-25T14:59:43.370991Z",
          "shell.execute_reply.started": "2023-10-25T14:59:41.649423Z",
          "shell.execute_reply": "2023-10-25T14:59:43.369972Z"
        },
        "trusted": true,
        "id": "FGLXIgji02x6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mergeData = pd.read_csv('/kaggle/working/mergeDataFeatureCandidates.csv')\n",
        "mergeData"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:59:43.372262Z",
          "iopub.execute_input": "2023-10-25T14:59:43.372946Z",
          "iopub.status.idle": "2023-10-25T14:59:43.722458Z",
          "shell.execute_reply.started": "2023-10-25T14:59:43.372906Z",
          "shell.execute_reply": "2023-10-25T14:59:43.720869Z"
        },
        "trusted": true,
        "id": "ZjbaFieE02x6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final feature selection"
      ],
      "metadata": {
        "id": "EhvkX4Fx02x6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# select features\n",
        "mergeData = mergeData[['weekOfYear_sin', 'weekOfYear_cos', 'dayOfWeek_sin', 'dayOfWeek_cos', 'dailyTrend', 'dailySeasonal', 'dailyResid', 'weeklyTrend', 'weeklySeasonal', 'weeklyResid', 'AggregateLoad_1dayLag', 'AggregateLoad_1weekLag', 'AggregateLoad_halfhourdiff', 'temperature', 'temp_daymax', 'AggregateLoad']]\n",
        "mergeData.info()\n",
        "\n",
        "# mergeData = mergeData[['AggregateLoad_1dayLag', 'AggregateLoad_1weekLag', 'dayOfWeek', 'temperature','AggregateLoad']]\n",
        "# mergeData = mergeData[['numMeters', 'temperature', 'minuteOfDay_sin', 'minuteOfDay_cos', 'dayOfWeek_sin', 'dayOfWeek_cos', 'weekOfYear_sin', 'weekOfYear_cos', 'AggregateLoad']]\n",
        "# mergeData = mergeData[['numMeters', 'minuteOfDay_sin', 'minuteOfDay_cos', 'dayOfWeek_sin', 'dayOfWeek_cos', 'weekOfYear_sin', 'weekOfYear_cos', 'AggregateLoad']]\n",
        "# mergeData = mergeData[['minuteOfDay_sin', 'minuteOfDay_cos', 'dayOfWeek_sin', 'dayOfWeek_cos', 'weekOfYear_sin', 'weekOfYear_cos', 'AggregateLoad']]\n",
        "# mergeData = mergeData[['AggregateLoad']]\n",
        "# remove features dues to feature permutation importance\n",
        "# mergeData.drop(columns=['numMeters', 'yearlySeasonal'], inplace=True)\n",
        "# mergeData.drop(columns=['temperature', 'AggregateLoad_1weekLag', 'temp_daymax'], inplace=True)\n",
        "# after looking at correlation matrix and hearing about overalp between cyclical encoding and seasinal decomp...\n",
        "# mergeData.drop(columns=['dewPoint', 'dayOfWeek_sin', 'minuteOfDay_sin', 'minuteOfDay_cos', 'weeklyTrend', 'weeklySeasonal', 'weeklyResid', 'temp_daymin', 'AggregateLoad_1dayLag'], inplace=True)\n",
        "# ok have to put those cyclical features back in...\n",
        "# mergeData.drop(columns=['dewPoint', 'weeklyTrend', 'weeklySeasonal', 'weeklyResid', 'temp_daymin', 'AggregateLoad_1dayLag'], inplace=True)\n",
        "# ok now drop these after feature importance...\n",
        "# mergeData.drop(columns=['yearlySeasonal', 'numMeters', 'minuteOfDay_sin', 'minuteOfDay_cos', 'AggregateLoad_weekdiff'], inplace=True)\n",
        "\n",
        "# going back to best feature set\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:59:43.724831Z",
          "iopub.execute_input": "2023-10-25T14:59:43.72523Z",
          "iopub.status.idle": "2023-10-25T14:59:43.750272Z",
          "shell.execute_reply.started": "2023-10-25T14:59:43.725198Z",
          "shell.execute_reply": "2023-10-25T14:59:43.748414Z"
        },
        "trusted": true,
        "id": "magmxx2002x6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mergeData.to_csv('/kaggle/working/mergeDataFinal.csv',index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:59:43.752363Z",
          "iopub.execute_input": "2023-10-25T14:59:43.752791Z",
          "iopub.status.idle": "2023-10-25T14:59:45.054336Z",
          "shell.execute_reply.started": "2023-10-25T14:59:43.752755Z",
          "shell.execute_reply": "2023-10-25T14:59:45.053235Z"
        },
        "trusted": true,
        "id": "pB-PiJNN02x7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mergeData = pd.read_csv('/kaggle/working/mergeDataFinal.csv')\n",
        "mergeData"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:59:45.055959Z",
          "iopub.execute_input": "2023-10-25T14:59:45.056545Z",
          "iopub.status.idle": "2023-10-25T14:59:45.24976Z",
          "shell.execute_reply.started": "2023-10-25T14:59:45.056509Z",
          "shell.execute_reply": "2023-10-25T14:59:45.248783Z"
        },
        "trusted": true,
        "id": "GOR9RWCD02x7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training, Validation, Testing Split"
      ],
      "metadata": {
        "id": "BuKivaGD02x8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the time series data into train, test, and validation datasets\n",
        "train_size = int(len(mergeData) * 0.7)  # 70% for training\n",
        "val_size = int(len(mergeData) * 0.2)   # 20% for validation\n",
        "test_size = len(mergeData) - val_size - train_size  # Remaining 10% for testing\n",
        "\n",
        "train_data = mergeData[:train_size].copy()\n",
        "train_data.reset_index(drop=True, inplace=True)\n",
        "val_data = mergeData[train_size:train_size+val_size].copy()\n",
        "val_data.reset_index(drop=True, inplace=True)\n",
        "test_data = mergeData[train_size+val_size:].copy()\n",
        "test_data.reset_index(drop=True, inplace=True)\n",
        "\n",
        "print('\\ntrain_data.head()\\n', train_data.head())\n",
        "print(train_data.info())\n",
        "print('\\nval_data.head()\\n', val_data.head())\n",
        "print(val_data.info())\n",
        "print('\\ntest_data.head()\\n', test_data.head())\n",
        "print(test_data.info())\n",
        "\n",
        "num_out_features = mergeData.shape[1]\n",
        "label_columns = ['AggregateLoad']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:59:45.251343Z",
          "iopub.execute_input": "2023-10-25T14:59:45.251951Z",
          "iopub.status.idle": "2023-10-25T14:59:45.317404Z",
          "shell.execute_reply.started": "2023-10-25T14:59:45.251915Z",
          "shell.execute_reply": "2023-10-25T14:59:45.315778Z"
        },
        "trusted": true,
        "id": "Ug2a0-TA02x8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction_plot(testY, test_predict):\n",
        "      len_prediction=[x for x in range(len(testY))]\n",
        "      plt.figure(figsize=(20,5))\n",
        "      plt.plot(len_prediction, testY, marker='.', label=\"actual\")\n",
        "      plt.plot(len_prediction, test_predict, 'r', label=\"prediction\")\n",
        "      plt.tight_layout()\n",
        "      sns.despine(top=True)\n",
        "      plt.subplots_adjust(left=0.07)\n",
        "      plt.ylabel('kWh per half hour', size=15)\n",
        "      plt.xlabel('Time step', size=15)\n",
        "      plt.legend(fontsize=15)\n",
        "      plt.show();"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:59:45.318991Z",
          "iopub.execute_input": "2023-10-25T14:59:45.319365Z",
          "iopub.status.idle": "2023-10-25T14:59:45.329535Z",
          "shell.execute_reply.started": "2023-10-25T14:59:45.319332Z",
          "shell.execute_reply": "2023-10-25T14:59:45.3277Z"
        },
        "trusted": true,
        "id": "yp4qMoGu02x8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Standardize the data"
      ],
      "metadata": {
        "id": "Q1Amvi3m02x8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the data\n",
        "train_mean = train_data.mean()\n",
        "train_std = train_data.std()\n",
        "\n",
        "train_data = (train_data - train_mean) / train_std\n",
        "val_data = (val_data - train_mean) / train_std\n",
        "test_data = (test_data - train_mean) / train_std\n",
        "\n",
        "mergeDataNormed = (mergeData - train_mean) / train_std"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:59:45.331389Z",
          "iopub.execute_input": "2023-10-25T14:59:45.331871Z",
          "iopub.status.idle": "2023-10-25T14:59:45.362855Z",
          "shell.execute_reply.started": "2023-10-25T14:59:45.331832Z",
          "shell.execute_reply": "2023-10-25T14:59:45.36104Z"
        },
        "trusted": true,
        "id": "WQgcqeC102x8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.to_csv('/kaggle/working/train_data.csv',index=False)\n",
        "val_data.to_csv('/kaggle/working/val_data.csv',index=False)\n",
        "test_data.to_csv('/kaggle/working/test_data.csv',index=False)\n",
        "mergeDataNormed.to_csv('/kaggle/working/mergeDataNormed.csv',index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:59:45.364654Z",
          "iopub.execute_input": "2023-10-25T14:59:45.36512Z",
          "iopub.status.idle": "2023-10-25T14:59:48.290397Z",
          "shell.execute_reply.started": "2023-10-25T14:59:45.365082Z",
          "shell.execute_reply": "2023-10-25T14:59:48.28931Z"
        },
        "trusted": true,
        "id": "8tjm6GAQ02x9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv('/kaggle/working/train_data.csv')\n",
        "val_data = pd.read_csv('/kaggle/working/val_data.csv')\n",
        "test_data = pd.read_csv('/kaggle/working/test_data.csv')\n",
        "mergeDataNormed = pd.read_csv('/kaggle/working/mergeDataNormed.csv')\n",
        "label_columns = ['AggregateLoad']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:59:48.292032Z",
          "iopub.execute_input": "2023-10-25T14:59:48.294108Z",
          "iopub.status.idle": "2023-10-25T14:59:48.64665Z",
          "shell.execute_reply.started": "2023-10-25T14:59:48.294035Z",
          "shell.execute_reply": "2023-10-25T14:59:48.645757Z"
        },
        "trusted": true,
        "id": "g8_uqRfU02x9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.info())\n",
        "print(val_data.info())\n",
        "print(test_data.info())\n",
        "print(mergeDataNormed.info())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:59:48.64908Z",
          "iopub.execute_input": "2023-10-25T14:59:48.649555Z",
          "iopub.status.idle": "2023-10-25T14:59:48.68885Z",
          "shell.execute_reply.started": "2023-10-25T14:59:48.649512Z",
          "shell.execute_reply": "2023-10-25T14:59:48.687225Z"
        },
        "trusted": true,
        "id": "dKue8aa302x9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize distribution of the features\n",
        "# df_std = (mergeData - train_mean) / train_std\n",
        "df_std = mergeDataNormed.melt(var_name='Column', value_name='Standardized')\n",
        "plt.figure(figsize=(12, 6))\n",
        "ax = sns.violinplot(x='Column', y='Standardized', data=df_std, size=15)\n",
        "_ = ax.set_xticklabels(mergeDataNormed.keys(), rotation=90)\n",
        "plt.title('Violin Plot', size=15)\n",
        "plt.savefig('violin_plot.png', format='png')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:59:48.690602Z",
          "iopub.execute_input": "2023-10-25T14:59:48.691028Z",
          "iopub.status.idle": "2023-10-25T14:59:52.620141Z",
          "shell.execute_reply.started": "2023-10-25T14:59:48.690996Z",
          "shell.execute_reply": "2023-10-25T14:59:52.61887Z"
        },
        "trusted": true,
        "id": "U_W0zoJJ02x9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mutual_info_score\n",
        "\n",
        "# Split the data into features and target\n",
        "X = mergeDataNormed.drop(columns=['AggregateLoad'])\n",
        "y = mergeDataNormed['AggregateLoad']\n",
        "\n",
        "# Calculate mutual information between each feature and the target variable\n",
        "mutual_information_scores = []\n",
        "for feature in X.columns:\n",
        "    mutual_information_score = mutual_info_score(X[feature], y)\n",
        "    mutual_information_scores.append([feature,mutual_information_score])\n",
        "\n",
        "MISdf = pd.DataFrame(mutual_information_scores, columns=['Feature', 'Mutual information score'])\n",
        "# Print the mutual information scores\n",
        "# print('Mutual information scores:', mutual_information_scores)\n",
        "print(MISdf.sort_values('Mutual information score', ascending=False))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:59:52.621939Z",
          "iopub.execute_input": "2023-10-25T14:59:52.622829Z",
          "iopub.status.idle": "2023-10-25T14:59:52.905014Z",
          "shell.execute_reply.started": "2023-10-25T14:59:52.622791Z",
          "shell.execute_reply": "2023-10-25T14:59:52.90345Z"
        },
        "trusted": true,
        "id": "pyD4UQ_Q02x9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas_profiling import ProfileReport\n",
        "\n",
        "# profile = ProfileReport(mergeDataNormed, tsmode=True, sortby=mergeDataNormed.index.astype(int))\n",
        "profile = ProfileReport(mergeDataNormed, tsmode=True)\n",
        "profile.to_file('mergeDataNormed profile_report.html')\n",
        "# profile"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T14:59:52.906745Z",
          "iopub.execute_input": "2023-10-25T14:59:52.907222Z",
          "iopub.status.idle": "2023-10-25T15:01:46.484966Z",
          "shell.execute_reply.started": "2023-10-25T14:59:52.90717Z",
          "shell.execute_reply": "2023-10-25T15:01:46.478846Z"
        },
        "trusted": true,
        "id": "nDH2QCLe02x-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions for preparing data for time series machine learning\n",
        "\n",
        "Not my work\n",
        "\n",
        "Credit to [Tensorflow Tutorial: Time series forecasting](https://www.tensorflow.org/tutorials/structured_data/time_series)"
      ],
      "metadata": {
        "id": "m2YK0uy102x-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WindowGenerator():\n",
        "    # https://www.tensorflow.org/tutorials/structured_data/time_series#1_indexes_and_offsets\n",
        "  def __init__(self, input_width, label_width, shift,\n",
        "               train_df=train_data, val_df=val_data, test_df=test_data,\n",
        "               label_columns=None):\n",
        "    # print('\\nWindowGenerator.__init__\\n')\n",
        "    # Store the raw data.\n",
        "    self.train_df = train_df\n",
        "    self.val_df = val_df\n",
        "    self.test_df = test_df\n",
        "    # print('\\nlabel_columns:\\n', label_columns)\n",
        "    # Work out the label column indices.\n",
        "    self.label_columns = label_columns\n",
        "    self.num_out_features = train_df.shape[1] # default to predicting all input columns\n",
        "\n",
        "    if label_columns is not None:\n",
        "      self.label_columns_indices = {name: i for i, name in\n",
        "                                    enumerate(label_columns)}\n",
        "      self.num_out_features = len(label_columns) # JS added this\n",
        "      # print('\\nself.num_out_features:', self.num_out_features)\n",
        "\n",
        "    self.column_indices = {name: i for i, name in\n",
        "                           enumerate(train_df.columns)}\n",
        "\n",
        "    # Work out the window parameters.\n",
        "    self.input_width = input_width\n",
        "    self.label_width = label_width\n",
        "    self.shift = shift\n",
        "\n",
        "    self.total_window_size = input_width + shift\n",
        "\n",
        "    self.input_slice = slice(0, input_width)\n",
        "    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
        "\n",
        "    self.label_start = self.total_window_size - self.label_width\n",
        "    self.labels_slice = slice(self.label_start, None)\n",
        "    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
        "\n",
        "  def __repr__(self):\n",
        "    return '\\n'.join([\n",
        "        f'Total window size: {self.total_window_size}',\n",
        "        f'Input indices: {self.input_indices}',\n",
        "        f'Label indices: {self.label_indices}',\n",
        "        f'Label column name(s): {self.label_columns}'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:23:24.670446Z",
          "iopub.execute_input": "2023-10-25T15:23:24.671108Z",
          "iopub.status.idle": "2023-10-25T15:23:24.686417Z",
          "shell.execute_reply.started": "2023-10-25T15:23:24.671068Z",
          "shell.execute_reply": "2023-10-25T15:23:24.684416Z"
        },
        "trusted": true,
        "id": "25WAQNxL02x-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_window(self, features):\n",
        "    # https://www.tensorflow.org/tutorials/structured_data/time_series#2_split\n",
        "  # print('\\nsplit_window\\n', features)\n",
        "  inputs = features[:, self.input_slice, :]\n",
        "  labels = features[:, self.labels_slice, :]\n",
        "  if self.label_columns is not None:\n",
        "    labels = tf.stack(\n",
        "        [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
        "        axis=-1)\n",
        "\n",
        "  # Slicing doesn't preserve static shape information, so set the shapes\n",
        "  # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
        "  inputs.set_shape([None, self.input_width, None])\n",
        "  labels.set_shape([None, self.label_width, None])\n",
        "\n",
        "  return inputs, labels\n",
        "\n",
        "WindowGenerator.split_window = split_window\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:23:24.689507Z",
          "iopub.execute_input": "2023-10-25T15:23:24.689955Z",
          "iopub.status.idle": "2023-10-25T15:23:24.707613Z",
          "shell.execute_reply.started": "2023-10-25T15:23:24.689913Z",
          "shell.execute_reply": "2023-10-25T15:23:24.705928Z"
        },
        "trusted": true,
        "id": "e2sFxKX102x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot(self, model=None, plot_col='AggregateLoad', max_subplots=3):\n",
        "    # https://www.tensorflow.org/tutorials/structured_data/time_series#3_plot\n",
        "  inputs, labels = self.example\n",
        "  plt.figure(figsize=(12, 8))\n",
        "  plot_col_index = self.column_indices[plot_col]\n",
        "  max_n = min(max_subplots, len(inputs))\n",
        "  for n in range(max_n):\n",
        "    plt.subplot(max_n, 1, n+1)\n",
        "    plt.ylabel(f'{plot_col} [normed]')\n",
        "    plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n",
        "             label='Inputs', marker='.', zorder=-10)\n",
        "\n",
        "    if self.label_columns:\n",
        "      label_col_index = self.label_columns_indices.get(plot_col, None)\n",
        "    else:\n",
        "      label_col_index = plot_col_index\n",
        "\n",
        "    if label_col_index is None:\n",
        "      continue\n",
        "\n",
        "    plt.scatter(self.label_indices, labels[n, :, label_col_index],\n",
        "                edgecolors='k', label='Labels', c='#2ca02c', s=64)\n",
        "    if model is not None:\n",
        "      predictions = model(inputs)\n",
        "      plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n",
        "                  marker='X', edgecolors='k', label='Predictions',\n",
        "                  c='#ff7f0e', s=64)\n",
        "\n",
        "    if n == 0:\n",
        "      plt.legend()\n",
        "\n",
        "  plt.xlabel('Time [h]')\n",
        "\n",
        "WindowGenerator.plot = plot"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:23:24.709048Z",
          "iopub.execute_input": "2023-10-25T15:23:24.710528Z",
          "iopub.status.idle": "2023-10-25T15:23:24.726825Z",
          "shell.execute_reply.started": "2023-10-25T15:23:24.710463Z",
          "shell.execute_reply": "2023-10-25T15:23:24.725632Z"
        },
        "trusted": true,
        "id": "9KMBaa0_02x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_dataset(self, data):\n",
        "    # https://www.tensorflow.org/tutorials/structured_data/time_series#4_create_tfdatadatasets\n",
        "  # print('\\nmake_dataset\\n', data)\n",
        "  data = np.array(data, dtype=np.float32)\n",
        "  ds = tf.keras.utils.timeseries_dataset_from_array(\n",
        "      data=data,\n",
        "      targets=None,\n",
        "      sequence_length=self.total_window_size,\n",
        "      sequence_stride=1,\n",
        "      shuffle=True,\n",
        "      seed=randomState,\n",
        "      batch_size=32,)\n",
        "\n",
        "  ds = ds.map(self.split_window)\n",
        "\n",
        "  return ds\n",
        "\n",
        "WindowGenerator.make_dataset = make_dataset"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:23:24.729277Z",
          "iopub.execute_input": "2023-10-25T15:23:24.730455Z",
          "iopub.status.idle": "2023-10-25T15:23:24.741148Z",
          "shell.execute_reply.started": "2023-10-25T15:23:24.730403Z",
          "shell.execute_reply": "2023-10-25T15:23:24.73985Z"
        },
        "trusted": true,
        "id": "e6u0gzWX02x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.tensorflow.org/tutorials/structured_data/time_series#4_create_tfdatadatasets\n",
        "@property\n",
        "def train(self):\n",
        "  return self.make_dataset(self.train_df)\n",
        "\n",
        "@property\n",
        "def val(self):\n",
        "  return self.make_dataset(self.val_df)\n",
        "\n",
        "@property\n",
        "def test(self):\n",
        "  return self.make_dataset(self.test_df)\n",
        "\n",
        "@property\n",
        "def example(self):\n",
        "  \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n",
        "  result = getattr(self, '_example', None)\n",
        "  if result is None:\n",
        "    # No example batch was found, so get one from the `.train` dataset\n",
        "    result = next(iter(self.train))\n",
        "    # And cache it for next time\n",
        "    self._example = result\n",
        "  return result\n",
        "\n",
        "WindowGenerator.train = train\n",
        "WindowGenerator.val = val\n",
        "WindowGenerator.test = test\n",
        "WindowGenerator.example = example"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:23:24.742461Z",
          "iopub.execute_input": "2023-10-25T15:23:24.743073Z",
          "iopub.status.idle": "2023-10-25T15:23:24.759388Z",
          "shell.execute_reply.started": "2023-10-25T15:23:24.743033Z",
          "shell.execute_reply": "2023-10-25T15:23:24.758058Z"
        },
        "trusted": true,
        "id": "jRiOc8bq02x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create data windows for time series forecasting"
      ],
      "metadata": {
        "id": "MmN4QNtk02x_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data for one-shot multi-step\n",
        "OUT_STEPS = 48 # 24 hour forecast\n",
        "# IN_STEPS = 336 # look back 1 week\n",
        "IN_STEPS = 48 # look back 1 day\n",
        "multi_window = WindowGenerator(input_width=IN_STEPS,\n",
        "                               label_width=OUT_STEPS,\n",
        "                               shift=OUT_STEPS,\n",
        "                               label_columns=['AggregateLoad'],\n",
        "                              train_df=train_data, val_df=val_data, test_df=test_data,)\n",
        "\n",
        "num_out_features = multi_window.num_out_features\n",
        "# print('\\nnum_out_features: ', num_out_features)\n",
        "multi_window.plot()\n",
        "multi_window"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:23:24.76087Z",
          "iopub.execute_input": "2023-10-25T15:23:24.761861Z",
          "iopub.status.idle": "2023-10-25T15:23:26.198218Z",
          "shell.execute_reply.started": "2023-10-25T15:23:24.76181Z",
          "shell.execute_reply": "2023-10-25T15:23:26.19674Z"
        },
        "trusted": true,
        "id": "k49AvCGR02yA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2GjhzsOL02yA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build and Train models"
      ],
      "metadata": {
        "id": "-bIRo-VM02yA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline persistence model\n",
        "\n",
        "Use a 1 week naive persistence model as a baseline to evaluate performance of the machine learning models we are building\n",
        "\n",
        "Georgios Tziolis, Chrysovalantis Spanias, Maria Theodoride, Spyros Theocharides, Javier Lopez-Lorente, Andreas Livera, George Makrides, George E. Georghiou,\n",
        "\n",
        "Short-term electric net load forecasting for solar-integrated distribution systems based on Bayesian neural networks and statistical post-processing,\n",
        "\n",
        "Energy,\n",
        "Volume 271,\n",
        "2023,\n",
        "127018,\n",
        "ISSN 0360-5442,\n",
        "\n",
        "https://doi.org/10.1016/j.energy.2023.127018."
      ],
      "metadata": {
        "id": "oBCRf0UU02yA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# capture performnce of models\n",
        "multi_val_performance = {}\n",
        "multi_test_performance = {}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:23:26.199795Z",
          "iopub.execute_input": "2023-10-25T15:23:26.200156Z",
          "iopub.status.idle": "2023-10-25T15:23:26.205792Z",
          "shell.execute_reply.started": "2023-10-25T15:23:26.200126Z",
          "shell.execute_reply": "2023-10-25T15:23:26.204281Z"
        },
        "trusted": true,
        "id": "3Cy9qOeu02yB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function to compile and fit models"
      ],
      "metadata": {
        "id": "4jLGsh_x02yB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_EPOCHS = 100\n",
        "\n",
        "def compile_and_fit(model, window, patience=5):\n",
        "  # https://www.tensorflow.org/tutorials/structured_data/time_series#linear_model\n",
        "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                                    patience=patience,\n",
        "                                                    mode='min')\n",
        "\n",
        "  model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
        "\n",
        "  checkpoint_filepath = '/tmp/' + model.name + '/checkpoint'\n",
        "  checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_filepath,\n",
        "                    monitor=\"val_loss\", mode=\"min\",\n",
        "                    save_best_only=True, verbose=1)\n",
        "\n",
        "  # print('\\nwindow.train:\\n', window.train)\n",
        "  # print('\\nwindow.val:\\n', window.val)\n",
        "  history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
        "                      validation_data=window.val,\n",
        "                      callbacks=[early_stopping, checkpoint])\n",
        "\n",
        "  # restore weights from epoch with best loss against validation dataset\n",
        "  model.load_weights(checkpoint_filepath)\n",
        "\n",
        "  return history\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:23:26.207287Z",
          "iopub.execute_input": "2023-10-25T15:23:26.207722Z",
          "iopub.status.idle": "2023-10-25T15:23:26.221423Z",
          "shell.execute_reply.started": "2023-10-25T15:23:26.207689Z",
          "shell.execute_reply": "2023-10-25T15:23:26.220158Z"
        },
        "trusted": true,
        "id": "lW5yDRS902yC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline Model: Naive 1 week persistence\n",
        "OneWeekNPeriods = 48 * 7\n",
        "NaiveForecast = mergeData.AggregateLoad.shift(OneWeekNPeriods).copy()\n",
        "\n",
        "print(NaiveForecast.info())\n",
        "print(NaiveForecast.describe())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:23:26.222847Z",
          "iopub.execute_input": "2023-10-25T15:23:26.223195Z",
          "iopub.status.idle": "2023-10-25T15:23:26.251262Z",
          "shell.execute_reply.started": "2023-10-25T15:23:26.223166Z",
          "shell.execute_reply": "2023-10-25T15:23:26.250044Z"
        },
        "trusted": true,
        "id": "HjR563nD02yC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize naive forecast and actuals for entire dataset\n",
        "prediction_plot(mergeData.AggregateLoad, NaiveForecast)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:23:26.258371Z",
          "iopub.execute_input": "2023-10-25T15:23:26.258822Z",
          "iopub.status.idle": "2023-10-25T15:23:26.836512Z",
          "shell.execute_reply.started": "2023-10-25T15:23:26.258773Z",
          "shell.execute_reply": "2023-10-25T15:23:26.835371Z"
        },
        "trusted": true,
        "id": "kPBzk-Xm02yC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize naive forecast and actuals for first 24 hours of the test dataset\n",
        "# print(train_size, val_size, test_size)\n",
        "# print(train_size+val_size)\n",
        "prediction_plot(mergeData.AggregateLoad[train_size+val_size:train_size+val_size+OUT_STEPS], NaiveForecast[train_size+val_size:train_size+val_size+OUT_STEPS])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:23:26.838093Z",
          "iopub.execute_input": "2023-10-25T15:23:26.838498Z",
          "iopub.status.idle": "2023-10-25T15:23:27.238361Z",
          "shell.execute_reply.started": "2023-10-25T15:23:26.838462Z",
          "shell.execute_reply": "2023-10-25T15:23:27.236944Z"
        },
        "trusted": true,
        "id": "BwNyth2n02yC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# standardize the baseline\n",
        "NaiveForecastNormed = NaiveForecast.transform(lambda x: (x - train_mean) / train_std)\n",
        "NaiveForecastNormed.describe()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:23:27.239951Z",
          "iopub.execute_input": "2023-10-25T15:23:27.240326Z",
          "iopub.status.idle": "2023-10-25T15:23:40.529154Z",
          "shell.execute_reply.started": "2023-10-25T15:23:27.240295Z",
          "shell.execute_reply": "2023-10-25T15:23:40.527994Z"
        },
        "trusted": true,
        "id": "2IWM63QS02yD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate error for baseline naive model (Normed)\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
        "\n",
        "# calculate error for naive model on validation set\n",
        "valNaiveMAE = mean_absolute_error(mergeDataNormed.AggregateLoad[train_size:train_size+val_size], NaiveForecastNormed.AggregateLoad[train_size:train_size+val_size])\n",
        "\n",
        "# calculate error for naive model on test set\n",
        "testNaiveMAE = mean_absolute_error(mergeDataNormed.AggregateLoad[train_size+val_size:], NaiveForecastNormed.AggregateLoad[train_size+val_size:])\n",
        "\n",
        "print('valNaiveMAE: ', valNaiveMAE)\n",
        "print('testNaiveMAE: ', testNaiveMAE)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:23:40.530765Z",
          "iopub.execute_input": "2023-10-25T15:23:40.53173Z",
          "iopub.status.idle": "2023-10-25T15:23:40.543545Z",
          "shell.execute_reply.started": "2023-10-25T15:23:40.531664Z",
          "shell.execute_reply": "2023-10-25T15:23:40.542353Z"
        },
        "trusted": true,
        "id": "oXFX2j7n02yH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate error for baseline naive model (not normed)\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
        "print('Naive Root Mean Squared Error(RMSE): %.2f; Naive Mean Absolute Error(MAE) : %.2f; Naive Mean Absolute Percantage Error(MAPE) : %.2f '\n",
        "      % (np.sqrt(mean_squared_error(mergeData.AggregateLoad[OneWeekNPeriods:], NaiveForecast[OneWeekNPeriods:])),\n",
        "         mean_absolute_error(mergeData.AggregateLoad[OneWeekNPeriods:], NaiveForecast[OneWeekNPeriods:]),\n",
        "         mean_absolute_percentage_error(mergeData.AggregateLoad[OneWeekNPeriods:], NaiveForecast[OneWeekNPeriods:])))\n",
        "\n",
        "# calculate error for naive model on validation set\n",
        "valNaiveMAE = mean_absolute_error(mergeData.AggregateLoad[train_size:train_size+val_size], NaiveForecast[train_size:train_size+val_size])\n",
        "\n",
        "# calculate error for naive model on test set\n",
        "testNaiveMAE = mean_absolute_error(mergeData.AggregateLoad[train_size+val_size:], NaiveForecast[train_size+val_size:])\n",
        "\n",
        "print('valNaiveMAE: ', valNaiveMAE)\n",
        "print('testNaiveMAE: ', testNaiveMAE)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:23:40.545067Z",
          "iopub.execute_input": "2023-10-25T15:23:40.54538Z",
          "iopub.status.idle": "2023-10-25T15:23:40.563971Z",
          "shell.execute_reply.started": "2023-10-25T15:23:40.545353Z",
          "shell.execute_reply": "2023-10-25T15:23:40.562595Z"
        },
        "trusted": true,
        "id": "hI2cfBXI02yH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for plotting the train and test loss curves\n",
        "def plot_model_loss(history):\n",
        "    plt.figure(figsize=(8,4))\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epochs')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.show()\n",
        "    return"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:23:40.565622Z",
          "iopub.execute_input": "2023-10-25T15:23:40.566065Z",
          "iopub.status.idle": "2023-10-25T15:23:40.572064Z",
          "shell.execute_reply.started": "2023-10-25T15:23:40.566035Z",
          "shell.execute_reply": "2023-10-25T15:23:40.571149Z"
        },
        "trusted": true,
        "id": "kk5d7GRU02yI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RepeatBaseline(tf.keras.Model):\n",
        "  def call(self, inputs):\n",
        "    return inputs\n",
        "\n",
        "repeat_baseline = RepeatBaseline()\n",
        "repeat_baseline.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
        "                        metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
        "\n",
        "multi_val_performance['Baseline'] = repeat_baseline.evaluate(mergeDataNormed.AggregateLoad[train_size:train_size+val_size], NaiveForecastNormed.AggregateLoad[train_size:train_size+val_size], verbose=0)\n",
        "multi_test_performance['Baseline'] = repeat_baseline.evaluate(mergeDataNormed.AggregateLoad[train_size+val_size:], NaiveForecastNormed.AggregateLoad[train_size+val_size:], verbose=0)\n",
        "print(multi_val_performance['Baseline'], multi_test_performance['Baseline'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:23:40.573351Z",
          "iopub.execute_input": "2023-10-25T15:23:40.574246Z",
          "iopub.status.idle": "2023-10-25T15:23:41.423306Z",
          "shell.execute_reply.started": "2023-10-25T15:23:40.574206Z",
          "shell.execute_reply": "2023-10-25T15:23:41.42249Z"
        },
        "trusted": true,
        "id": "aZx49fZ-02yI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi Layer Perceptron (MLP) Model"
      ],
      "metadata": {
        "id": "skNRbkaw02yI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "multi_MLP_model = tf.keras.Sequential([\n",
        "    # Take the last time step.\n",
        "    # Shape [batch, time, features] => [batch, 1, features]\n",
        "    tf.keras.layers.Lambda(lambda x: x[:, -1:, :]),\n",
        "    # Shape => [batch, 1, dense_units]\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    # tf.keras.layers.Dense(32, activation='relu'),\n",
        "    # Shape => [batch, out_steps*features]\n",
        "    tf.keras.layers.Dense(OUT_STEPS*num_out_features,\n",
        "                          kernel_initializer=tf.initializers.zeros()),\n",
        "    # Shape => [batch, out_steps, features]\n",
        "    tf.keras.layers.Reshape([OUT_STEPS, num_out_features])\n",
        "], name=\"MLP\")\n",
        "\n",
        "history = compile_and_fit(multi_MLP_model, multi_window)\n",
        "multi_MLP_model.save('multi_MLP_model.keras')\n",
        "plot_model_loss(history)\n",
        "\n",
        "multi_val_performance['MLP'] = multi_MLP_model.evaluate(multi_window.val)\n",
        "multi_test_performance['MLP'] = multi_MLP_model.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot(multi_MLP_model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:23:41.424621Z",
          "iopub.execute_input": "2023-10-25T15:23:41.425148Z",
          "iopub.status.idle": "2023-10-25T15:27:00.47812Z",
          "shell.execute_reply.started": "2023-10-25T15:23:41.425117Z",
          "shell.execute_reply": "2023-10-25T15:27:00.47707Z"
        },
        "trusted": true,
        "id": "lMnsWyFw02yI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_out_features"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:27:00.479551Z",
          "iopub.execute_input": "2023-10-25T15:27:00.480816Z",
          "iopub.status.idle": "2023-10-25T15:27:00.488545Z",
          "shell.execute_reply.started": "2023-10-25T15:27:00.480777Z",
          "shell.execute_reply": "2023-10-25T15:27:00.487231Z"
        },
        "trusted": true,
        "id": "RoPvfE-X02yJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolutional Neural Network (CNN) Model\n",
        "\n"
      ],
      "metadata": {
        "id": "5J9g5yGd02yJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CONV_WIDTH = 10\n",
        "multi_cnn_model = tf.keras.Sequential([\n",
        "    # Shape [batch, time, features] => [batch, CONV_WIDTH, features]\n",
        "    tf.keras.layers.Lambda(lambda x: x[:, -CONV_WIDTH:, :]),\n",
        "    # Shape => [batch, 1, conv_units]\n",
        "    tf.keras.layers.Conv1D(64, activation='relu', kernel_size=(CONV_WIDTH)),\n",
        "    # Shape => [batch, 1,  out_steps*features]\n",
        "    # tf.keras.layers.Dense(32),\n",
        "    tf.keras.layers.Dense(OUT_STEPS*num_out_features,\n",
        "                          kernel_initializer=tf.initializers.zeros()),\n",
        "    # Shape => [batch, out_steps, features]\n",
        "    tf.keras.layers.Reshape([OUT_STEPS, num_out_features])\n",
        "], name=\"CNN\")\n",
        "\n",
        "history = compile_and_fit(multi_cnn_model, multi_window)\n",
        "multi_cnn_model.save('multi_cnn_model.keras')\n",
        "plot_model_loss(history)\n",
        "# IPython.display.clear_output()\n",
        "\n",
        "multi_val_performance['CNN'] = multi_cnn_model.evaluate(multi_window.val)\n",
        "multi_test_performance['CNN'] = multi_cnn_model.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot(multi_cnn_model)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:27:00.492822Z",
          "iopub.execute_input": "2023-10-25T15:27:00.493235Z",
          "iopub.status.idle": "2023-10-25T15:28:34.100159Z",
          "shell.execute_reply.started": "2023-10-25T15:27:00.493199Z",
          "shell.execute_reply": "2023-10-25T15:28:34.098921Z"
        },
        "trusted": true,
        "id": "Xi1oU14-02yJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recurrent Neural Network (RNN) Model"
      ],
      "metadata": {
        "id": "V0lVINIX02yJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "multi_rnn_model = tf.keras.Sequential([\n",
        "    # tf.keras.layers.SimpleRNN(32, return_sequences=True),\n",
        "    # Shape => [batch, out_steps*features].\n",
        "    tf.keras.layers.SimpleRNN(64, return_sequences=False),\n",
        "    tf.keras.layers.Dense(OUT_STEPS*num_out_features,\n",
        "                          kernel_initializer=tf.initializers.zeros()),\n",
        "    # Shape => [batch, out_steps, features].\n",
        "    tf.keras.layers.Reshape([OUT_STEPS, num_out_features])\n",
        "], name=\"RNN\")\n",
        "\n",
        "history = compile_and_fit(multi_rnn_model, multi_window)\n",
        "plot_model_loss(history)\n",
        "multi_rnn_model.save('multi_rnn_model.keras')\n",
        "# IPython.display.clear_output()\n",
        "\n",
        "multi_val_performance['RNN'] = multi_rnn_model.evaluate(multi_window.val)\n",
        "multi_test_performance['RNN'] = multi_rnn_model.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot(multi_rnn_model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:28:34.102153Z",
          "iopub.execute_input": "2023-10-25T15:28:34.103377Z",
          "iopub.status.idle": "2023-10-25T15:32:16.668099Z",
          "shell.execute_reply.started": "2023-10-25T15:28:34.103331Z",
          "shell.execute_reply": "2023-10-25T15:32:16.666947Z"
        },
        "trusted": true,
        "id": "tqleFivl02yJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Long Short Term Memory (LSTM) Model"
      ],
      "metadata": {
        "id": "8b0LpLUK02yK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "multi_lstm_model = tf.keras.Sequential([\n",
        "    # Shape [batch, time, features] => [batch, lstm_units].\n",
        "    # tf.keras.layers.LSTM(32,return_sequences=True),\n",
        "    tf.keras.layers.LSTM(64,return_sequences=False),\n",
        "    # Shape => [batch, out_steps*features].\n",
        "    tf.keras.layers.Dense(OUT_STEPS*num_out_features,\n",
        "                          kernel_initializer=tf.initializers.zeros()),\n",
        "    # Shape => [batch, out_steps, features].\n",
        "    tf.keras.layers.Reshape([OUT_STEPS, num_out_features])\n",
        "], name=\"LSTM\")\n",
        "\n",
        "start_time = time.time()\n",
        "history = compile_and_fit(multi_lstm_model, multi_window)\n",
        "print('%s seconds' % (time.time() - start_time))\n",
        "multi_lstm_model.save('multi_lstm_model.keras')\n",
        "plot_model_loss(history)\n",
        "# IPython.display.clear_output()\n",
        "\n",
        "multi_val_performance['LSTM'] = multi_lstm_model.evaluate(multi_window.val)\n",
        "multi_test_performance['LSTM'] = multi_lstm_model.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot(multi_lstm_model)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:32:16.669797Z",
          "iopub.execute_input": "2023-10-25T15:32:16.670326Z",
          "iopub.status.idle": "2023-10-25T15:40:26.224661Z",
          "shell.execute_reply.started": "2023-10-25T15:32:16.670293Z",
          "shell.execute_reply": "2023-10-25T15:40:26.22342Z"
        },
        "trusted": true,
        "id": "iB7dJHoU02yK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GRU Model"
      ],
      "metadata": {
        "id": "hrxKIZC302yK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "multi_gru_model = tf.keras.Sequential([\n",
        "    # Shape [batch, time, features] => [batch, lstm_units].\n",
        "    # Adding more `lstm_units` just overfits more quickly.\n",
        "    # tf.keras.layers.GRU(32, return_sequences=True),\n",
        "    tf.keras.layers.GRU(64, return_sequences=False),\n",
        "    # Shape => [batch, out_steps*features].\n",
        "    tf.keras.layers.Dense(OUT_STEPS*num_out_features,\n",
        "                          kernel_initializer=tf.initializers.zeros()),\n",
        "    # Shape => [batch, out_steps, features].\n",
        "    tf.keras.layers.Reshape([OUT_STEPS, num_out_features])\n",
        "], name=\"GRU\")\n",
        "\n",
        "start_time = time.time()\n",
        "history = compile_and_fit(multi_gru_model, multi_window)\n",
        "print('%s seconds' % (time.time() - start_time))\n",
        "multi_gru_model.save('multi_gru_model.keras')\n",
        "plot_model_loss(history)\n",
        "# IPython.display.clear_output()\n",
        "\n",
        "multi_val_performance['GRU'] = multi_gru_model.evaluate(multi_window.val, verbose=0)\n",
        "multi_test_performance['GRU'] = multi_gru_model.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot(multi_gru_model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:40:26.226066Z",
          "iopub.execute_input": "2023-10-25T15:40:26.226402Z",
          "iopub.status.idle": "2023-10-25T15:51:26.6536Z",
          "shell.execute_reply.started": "2023-10-25T15:40:26.226355Z",
          "shell.execute_reply": "2023-10-25T15:51:26.652552Z"
        },
        "trusted": true,
        "id": "kHThbSLG02yK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation and Selection"
      ],
      "metadata": {
        "id": "ZzdfxmVR02yL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "print('\\nValidation Performance:\\n', multi_val_performance)\n",
        "print('\\nTest Performance:\\n', multi_test_performance)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T21:24:41.544556Z",
          "iopub.execute_input": "2023-10-13T21:24:41.544831Z",
          "iopub.status.idle": "2023-10-13T21:24:41.549833Z",
          "shell.execute_reply.started": "2023-10-13T21:24:41.544806Z",
          "shell.execute_reply": "2023-10-13T21:24:41.548602Z"
        },
        "id": "BL325hDF02yL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.arange(len(multi_test_performance))\n",
        "width = 0.3\n",
        "\n",
        "metric_name = 'mean_absolute_error'\n",
        "metric_index = multi_lstm_model.metrics_names.index('mean_absolute_error')\n",
        "val_mae = [v[metric_index] for v in multi_val_performance.values()]\n",
        "test_mae = [v[metric_index] for v in multi_test_performance.values()]\n",
        "\n",
        "plt.bar(x - 0.17, val_mae, width, label='Validation')\n",
        "plt.bar(x + 0.17, test_mae, width, label='Test')\n",
        "plt.xticks(ticks=x, labels=multi_test_performance.keys(),\n",
        "           rotation=45)\n",
        "plt.ylabel(f'Mean Absolute Error (MAE)')\n",
        "_ = plt.legend()\n",
        "plt.title(f'Model Performance')\n",
        "plt.savefig('model performance.png', format='png')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:51:26.65563Z",
          "iopub.execute_input": "2023-10-25T15:51:26.656076Z",
          "iopub.status.idle": "2023-10-25T15:51:27.093314Z",
          "shell.execute_reply.started": "2023-10-25T15:51:26.656038Z",
          "shell.execute_reply": "2023-10-25T15:51:27.091866Z"
        },
        "trusted": true,
        "id": "a62r763w02yL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CONV_WIDTH = 10 # CNN model would not load without this...\n",
        "# restore models from file\n",
        "multi_MLP_model = tf.keras.models.load_model('multi_MLP_model.keras')\n",
        "multi_cnn_model = tf.keras.models.load_model('multi_cnn_model.keras')\n",
        "multi_rnn_model = tf.keras.models.load_model('multi_rnn_model.keras')\n",
        "multi_lstm_model = tf.keras.models.load_model('multi_lstm_model.keras')\n",
        "multi_gru_model = tf.keras.models.load_model('multi_gru_model.keras')\n",
        "model_list = [multi_MLP_model, multi_cnn_model, multi_rnn_model, multi_lstm_model, multi_gru_model]\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:51:27.095149Z",
          "iopub.execute_input": "2023-10-25T15:51:27.095596Z",
          "iopub.status.idle": "2023-10-25T15:51:29.5441Z",
          "shell.execute_reply.started": "2023-10-25T15:51:27.095556Z",
          "shell.execute_reply": "2023-10-25T15:51:29.542881Z"
        },
        "trusted": true,
        "id": "1Kbw4aZ802yL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model in model_list:\n",
        "    print(model.name)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:51:29.545506Z",
          "iopub.execute_input": "2023-10-25T15:51:29.545873Z",
          "iopub.status.idle": "2023-10-25T15:51:29.551871Z",
          "shell.execute_reply.started": "2023-10-25T15:51:29.54584Z",
          "shell.execute_reply": "2023-10-25T15:51:29.550279Z"
        },
        "trusted": true,
        "id": "hLYnhRlY02yL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# store the evaluation results for all models\n",
        "import pickle\n",
        "with open('model eval results.pkl', 'wb') as f:\n",
        "    pickle.dump(multi_val_performance, f)\n",
        "\n",
        "with open('model test results.pkl', 'wb') as f:\n",
        "    pickle.dump(multi_test_performance, f)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:51:29.553355Z",
          "iopub.execute_input": "2023-10-25T15:51:29.553736Z",
          "iopub.status.idle": "2023-10-25T15:51:29.565802Z",
          "shell.execute_reply.started": "2023-10-25T15:51:29.553664Z",
          "shell.execute_reply": "2023-10-25T15:51:29.564462Z"
        },
        "trusted": true,
        "id": "wCoQZgM102yM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the evaluation results for all models\n",
        "with open('model eval results.pkl', 'rb') as f:\n",
        "    multi_val_performance = pickle.load(f)\n",
        "\n",
        "with open('model test results.pkl', 'rb') as f:\n",
        "    multi_test_performance = pickle.load(f)\n",
        "\n",
        "print(multi_val_performance)\n",
        "print(multi_test_performance)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:51:29.567315Z",
          "iopub.execute_input": "2023-10-25T15:51:29.567729Z",
          "iopub.status.idle": "2023-10-25T15:51:29.579919Z",
          "shell.execute_reply.started": "2023-10-25T15:51:29.567696Z",
          "shell.execute_reply": "2023-10-25T15:51:29.578952Z"
        },
        "trusted": true,
        "id": "xw-SPNCa02yM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Evaluation (methods that require models already built)"
      ],
      "metadata": {
        "id": "73AuZW5U02yM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to create time series dataset for feature permutation\n",
        "def generateFeatPermWindow(input_width=IN_STEPS,\n",
        "                               label_width=OUT_STEPS,\n",
        "                               shift=OUT_STEPS,\n",
        "                               label_columns=None,\n",
        "                                cols_to_shuffle=None,\n",
        "                              train_df=train_data, val_df=val_data, test_df=test_data):\n",
        "\n",
        "    train = train_df.copy()\n",
        "    val = val_df.copy()\n",
        "    test = test_df.copy()\n",
        "\n",
        "    # randomly shuffle shuffle the specified columns\n",
        "    for col in cols_to_shuffle:\n",
        "        train[col] = train[col].sample(frac=1, replace=False, random_state=randomState, ignore_index=True)\n",
        "        val[col] = val[col].sample(frac=1, replace=False, random_state=randomState, ignore_index=True)\n",
        "        test[col] = test[col].sample(frac=1, replace=False, random_state=randomState, ignore_index=True)\n",
        "\n",
        "    \"\"\"\n",
        "    print('train NaNs: ', train.isnull().sum().sum())\n",
        "    print('val NaNs: ', val.isnull().sum().sum())\n",
        "    print('val NaNs:\\n', val[val.isna().any(axis=1)])\n",
        "    print('test NaNs: ', test.isnull().sum().sum())\n",
        "    print('test NaNs:\\n', test[test.isna().any(axis=1)])\n",
        "    \"\"\"\n",
        "\n",
        "    feat_perm_window = WindowGenerator(input_width=IN_STEPS,\n",
        "                               label_width=OUT_STEPS,\n",
        "                               shift=OUT_STEPS,\n",
        "                               label_columns=label_columns,\n",
        "                              train_df=train, val_df=val, test_df=test,)\n",
        "\n",
        "    return feat_perm_window\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:51:29.588317Z",
          "iopub.execute_input": "2023-10-25T15:51:29.588728Z",
          "iopub.status.idle": "2023-10-25T15:51:29.599525Z",
          "shell.execute_reply.started": "2023-10-25T15:51:29.588665Z",
          "shell.execute_reply": "2023-10-25T15:51:29.598245Z"
        },
        "trusted": true,
        "id": "wgcsuxTx02yM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.inspection import permutation_importance\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define a function to calculate the permutation importance of a feature group for a given model\n",
        "def calculate_permutation_importance_group(model, feature_group, baseline_val_perf, baseline_test_perf):\n",
        "    \"\"\"Calculates the permutation importance of a feature group for a given model.\n",
        "\n",
        "    Args:\n",
        "        model: The model to calculate the permutation importance for.\n",
        "        feature_group: A list of the features in the feature group.\n",
        "        baseline_val_perf: baseline performance (in MAE) of the model using all features for the validation set\n",
        "        baseline_test_perf: baseline performance (in MAE) of the model using all features for the test set\n",
        "\n",
        "    Returns:\n",
        "        The permutation importance of the feature group for the given model.\n",
        "    \"\"\"\n",
        "\n",
        "    # Shuffle the values of the features in the feature group\n",
        "    feat_perm_window = generateFeatPermWindow(input_width=IN_STEPS,\n",
        "                               label_width=OUT_STEPS,\n",
        "                               shift=OUT_STEPS,\n",
        "                               label_columns=label_columns,\n",
        "                                cols_to_shuffle=feature_group,\n",
        "                              train_df=train_data, val_df=val_data, test_df=test_data)\n",
        "\n",
        "    # model.fit(X_shuffled, y)\n",
        "    val_perf_shuffle = model.evaluate(feat_perm_window.val, verbose=1)[1] # MAE\n",
        "\n",
        "    # Calculate the permutation importance\n",
        "    # importance = np.mean(y - y_pred)\n",
        "    importance = val_perf_shuffle - baseline_val_perf\n",
        "\n",
        "    print('\\nModel: ', model.name, feature_group, 'importance: ', importance)\n",
        "\n",
        "    return importance"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:51:29.601508Z",
          "iopub.execute_input": "2023-10-25T15:51:29.601997Z",
          "iopub.status.idle": "2023-10-25T15:51:29.616387Z",
          "shell.execute_reply.started": "2023-10-25T15:51:29.601965Z",
          "shell.execute_reply": "2023-10-25T15:51:29.615487Z"
        },
        "trusted": true,
        "id": "zsEKBq6p02yM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to visualize the permutation importances for a given feature using a stacked bar chart\n",
        "def visualize_permutation_importances_stacked_bar_stackplot(model, permutation_importances):\n",
        "    \"\"\"Visualizes the permutation importances for a given feature using a stacked bar chart created with the plt.stackplot() function.\n",
        "\n",
        "    Args:\n",
        "        feature: The feature to visualize the permutation importances for.\n",
        "        permutation_importances: A dictionary mapping the model names to the permutation importances for the given feature.\n",
        "    \"\"\"\n",
        "\n",
        "    # Get the permutation importances for each feature in a list\n",
        "    importances = sorted(permutation_importances.items(), key=itemgetter(1), reverse=True)\n",
        "    permutation_importances_values = list(importances.values())\n",
        "\n",
        "    # Create a bar chart of the permutation importances\n",
        "    plt.bar(importances.keys(), permutation_importances_values)\n",
        "    plt.xlabel('Feature')\n",
        "    plt.ylabel('Permutation Importance')\n",
        "    plt.title('Permutation Importances for Model: {}'.format(model))\n",
        "    plt.legend(importances.keys())\n",
        "    plt.tick_params(rotation=45)\n",
        "    plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:51:29.618039Z",
          "iopub.execute_input": "2023-10-25T15:51:29.618789Z",
          "iopub.status.idle": "2023-10-25T15:51:29.632949Z",
          "shell.execute_reply.started": "2023-10-25T15:51:29.618747Z",
          "shell.execute_reply": "2023-10-25T15:51:29.631988Z"
        },
        "trusted": true,
        "id": "y_uHsbQ102yM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Permutation Feature Importance"
      ],
      "metadata": {
        "id": "Rt2n_q8e02yN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the permutation feature importance for each model and visualize the results\n",
        "# cyclically encoded features need to be grouped together for the purposes of feature permutation importance\n",
        "feature_groups = {\n",
        "    'weekOfYear': ['weekOfYear_sin', 'weekOfYear_cos'],\n",
        "    'dayOfWeek': ['dayOfWeek_sin', 'dayOfWeek_cos'],\n",
        "#    'minuteOfDay': ['minuteOfDay_sin', 'minuteOfDay_cos'],\n",
        "}\n",
        "\n",
        "grouped_features = [value for key, value in feature_groups.items() for value in value]\n",
        "print('grouped_features: ', grouped_features, '\\n')\n",
        "\n",
        "# add individual features as feature groups of one\n",
        "for feature in val_data.columns:\n",
        "    if feature not in grouped_features:\n",
        "        feature_groups[feature] = [feature]\n",
        "\n",
        "print('feature_groups: ', feature_groups)\n",
        "\n",
        "permutation_importances_groups = {}\n",
        "for model in model_list:\n",
        "    # calculate baseline model performance with all features\n",
        "    print('\\ncalculate baseline model performance with all features.\\n', model.name)\n",
        "    val_perf = model.evaluate(multi_window.val, verbose=1)[1] # MAE\n",
        "    test_perf = model.evaluate(multi_window.test, verbose=1)[1] # MAE\n",
        "\n",
        "    for feature_group_name, feature_group in feature_groups.items():\n",
        "        permutation_importance = calculate_permutation_importance_group(model, feature_group, val_perf, test_perf)\n",
        "        if model.name not in permutation_importances_groups:\n",
        "            permutation_importances_groups[model.name] = {}\n",
        "        permutation_importances_groups[model.name][feature_group_name] = permutation_importance\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:51:29.634536Z",
          "iopub.execute_input": "2023-10-25T15:51:29.635562Z",
          "iopub.status.idle": "2023-10-25T15:54:03.78475Z",
          "shell.execute_reply.started": "2023-10-25T15:51:29.635518Z",
          "shell.execute_reply": "2023-10-25T15:54:03.783741Z"
        },
        "trusted": true,
        "id": "4vS27Rtb02yN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "permutation_importances_groups"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:54:03.786529Z",
          "iopub.execute_input": "2023-10-25T15:54:03.78708Z",
          "iopub.status.idle": "2023-10-25T15:54:03.796132Z",
          "shell.execute_reply.started": "2023-10-25T15:54:03.787048Z",
          "shell.execute_reply": "2023-10-25T15:54:03.794617Z"
        },
        "trusted": true,
        "id": "vmp1kvjp02yN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import itemgetter, attrgetter\n",
        "# Define a function to visualize the permutation importances for a given feature using a stacked bar chart\n",
        "def visualize_permutation_importances_stacked_bar_stackplot(model, permutation_importances):\n",
        "    \"\"\"Visualizes the permutation importances for a given feature using a stacked bar chart created with the plt.stackplot() function.\n",
        "\n",
        "    Args:\n",
        "        feature: The feature to visualize the permutation importances for.\n",
        "        permutation_importances: A dictionary mapping the model names to the permutation importances for the given feature.\n",
        "    \"\"\"\n",
        "\n",
        "    # Get the permutation importances for each feature in a list\n",
        "    importances = sorted(permutation_importances.items(), key=itemgetter(1), reverse=True)\n",
        "    print(importances)\n",
        "    df = pd.DataFrame(importances, columns=['label', 'value'])\n",
        "    labels = df['label'].tolist()\n",
        "    values = df['value'].tolist()\n",
        "\n",
        "\n",
        "    # Create a stacked bar chart of the permutation importances\n",
        "    plt.bar(labels, values)\n",
        "    plt.xlabel('Feature')\n",
        "    plt.ylabel('Permutation Importance')\n",
        "    plt.title('Permutation Importances for Model: {}'.format(model))\n",
        "    plt.legend(labels)\n",
        "    plt.tick_params(rotation=90)\n",
        "    plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:54:03.797507Z",
          "iopub.execute_input": "2023-10-25T15:54:03.797955Z",
          "iopub.status.idle": "2023-10-25T15:54:03.810544Z",
          "shell.execute_reply.started": "2023-10-25T15:54:03.797922Z",
          "shell.execute_reply": "2023-10-25T15:54:03.809662Z"
        },
        "trusted": true,
        "id": "WNauJu4x02yN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the permutation importances for each feature using a stacked bar chart\n",
        "for model, permutation_importances in permutation_importances_groups.items():\n",
        "    visualize_permutation_importances_stacked_bar_stackplot(model, permutation_importances)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:54:03.812719Z",
          "iopub.execute_input": "2023-10-25T15:54:03.813393Z",
          "iopub.status.idle": "2023-10-25T15:54:05.587978Z",
          "shell.execute_reply.started": "2023-10-25T15:54:03.813359Z",
          "shell.execute_reply": "2023-10-25T15:54:05.586755Z"
        },
        "trusted": true,
        "id": "8XfqLboZ02yN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Best Model Results"
      ],
      "metadata": {
        "id": "np16fsJ902yO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Single Day results: Benchmark, GRU model and actuals"
      ],
      "metadata": {
        "id": "wGog_7zl02yO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build a single record dataset from start of the test dataset\n",
        "# print(mergeDataNormed)\n",
        "# print(train_size+test_size-IN_STEPS)\n",
        "# print(mergeDataNormed.iloc[train_size+test_size-IN_STEPS:train_size+test_size])\n",
        "\n",
        "oneDay_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
        "      data=test_data[:IN_STEPS],\n",
        "      targets=None,\n",
        "      sequence_length=IN_STEPS,\n",
        "      sequence_stride=1,\n",
        "      shuffle=False,\n",
        "      batch_size=32,)\n",
        "\n",
        "# get the prediction\n",
        "testYhatNormed = multi_gru_model.predict(oneDay_ds)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:54:05.589569Z",
          "iopub.execute_input": "2023-10-25T15:54:05.590045Z",
          "iopub.status.idle": "2023-10-25T15:54:06.188935Z",
          "shell.execute_reply.started": "2023-10-25T15:54:05.590003Z",
          "shell.execute_reply": "2023-10-25T15:54:06.187905Z"
        },
        "trusted": true,
        "id": "ShcgP2V502yO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(testYhatNormed) # prediction for all input columns\n",
        "print(testYhatNormed[0,:,-1]) # prediction for target column, aggregate load"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:54:06.190927Z",
          "iopub.execute_input": "2023-10-25T15:54:06.19165Z",
          "iopub.status.idle": "2023-10-25T15:54:06.198972Z",
          "shell.execute_reply.started": "2023-10-25T15:54:06.191605Z",
          "shell.execute_reply": "2023-10-25T15:54:06.197725Z"
        },
        "trusted": true,
        "id": "qebjbe-002yO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Invert standardization\n",
        "testYhat = (np.array(testYhatNormed) * np.array(train_std)) + np.array(train_mean)\n",
        "\n",
        "# print(testYhat)\n",
        "print(testYhat[0,:,-1])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:54:06.200637Z",
          "iopub.execute_input": "2023-10-25T15:54:06.201713Z",
          "iopub.status.idle": "2023-10-25T15:54:06.219443Z",
          "shell.execute_reply.started": "2023-10-25T15:54:06.201642Z",
          "shell.execute_reply": "2023-10-25T15:54:06.218358Z"
        },
        "trusted": true,
        "id": "RgIzDspk02yO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Naive prediction, GRU prediction and Actuals for first 24 hours of the test set (normed values)\n",
        "len_prediction=[x for x in range(len(testYhat[0,:,-1]))]\n",
        "plt.figure(figsize=(10,5))\n",
        "# plt.plot(len_prediction, test_data[:OUT_STEPS].AggregateLoad, marker='.', label=\"actual\")\n",
        "plt.plot(len_prediction, mergeDataNormed.AggregateLoad[train_size+val_size:train_size+val_size+OUT_STEPS], marker='.', label=\"Actual\")\n",
        "plt.plot(len_prediction, testYhatNormed[0,:,-1], 'r', label=\"GRU prediction\")\n",
        "plt.plot(len_prediction, NaiveForecastNormed[train_size+val_size:train_size+val_size+OUT_STEPS].AggregateLoad, 'g', label=\"Baseline prediction\")\n",
        "\n",
        "plt.tight_layout()\n",
        "sns.despine(top=True)\n",
        "plt.subplots_adjust(left=0.07)\n",
        "plt.ylabel('kWh per half hour (Standardized)', size=15)\n",
        "plt.xlabel('Time (half-hours)', size=15)\n",
        "plt.legend(fontsize=15)\n",
        "plt.title('Baseline, Prediction and Actuals (Standardized)', size=15)\n",
        "plt.show();\n",
        "plt.savefig('Baseline, Prediction and Actuals (Standardized).png', format='png')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:54:06.221117Z",
          "iopub.execute_input": "2023-10-25T15:54:06.221502Z",
          "iopub.status.idle": "2023-10-25T15:54:06.58633Z",
          "shell.execute_reply.started": "2023-10-25T15:54:06.221464Z",
          "shell.execute_reply": "2023-10-25T15:54:06.585084Z"
        },
        "trusted": true,
        "id": "Izd66jWa02yP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate error for baseline naive model (Normed) first 24 hours of test set\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
        "\n",
        "# calculate error for baseline naive model on validation set\n",
        "valBaselineMAE = mean_absolute_error(mergeDataNormed.AggregateLoad[train_size:train_size+OUT_STEPS], NaiveForecastNormed.AggregateLoad[train_size:train_size+OUT_STEPS])\n",
        "\n",
        "# calculate error for baseline naive model on test set\n",
        "testBaselineMAE = mean_absolute_error(mergeDataNormed.AggregateLoad[train_size+val_size:train_size+val_size+OUT_STEPS], NaiveForecastNormed.AggregateLoad[train_size+val_size:train_size+val_size+OUT_STEPS])\n",
        "\n",
        "print('valBaselineMAE: ', valBaselineMAE)\n",
        "print('testBaselineMAE: ', testBaselineMAE)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:54:06.588226Z",
          "iopub.execute_input": "2023-10-25T15:54:06.588956Z",
          "iopub.status.idle": "2023-10-25T15:54:06.600224Z",
          "shell.execute_reply.started": "2023-10-25T15:54:06.588913Z",
          "shell.execute_reply": "2023-10-25T15:54:06.599015Z"
        },
        "trusted": true,
        "id": "r9KZjAp302yP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len_prediction=[x for x in range(len(testYhat[0,:,-1]))]\n",
        "plt.figure(figsize=(10,5))\n",
        "# plt.plot(len_prediction, test_data[:OUT_STEPS].AggregateLoad, marker='.', label=\"actual\")\n",
        "plt.plot(len_prediction, mergeData.AggregateLoad[train_size+val_size:train_size+val_size+OUT_STEPS], marker='.', label=\"Actual\")\n",
        "plt.plot(len_prediction, testYhat[0,:,-1], 'r', label=\"GRU prediction\")\n",
        "plt.plot(len_prediction, NaiveForecast[train_size+val_size:train_size+val_size+OUT_STEPS], 'g', label=\"Baseline prediction\")\n",
        "\n",
        "plt.tight_layout()\n",
        "sns.despine(top=True)\n",
        "plt.subplots_adjust(left=0.07)\n",
        "plt.ylabel('kWh per half hour', size=15)\n",
        "plt.xlabel('Hour', size=15)\n",
        "plt.legend(fontsize=15)\n",
        "plt.title('Baseline, Prediction and Actuals', size=15)\n",
        "plt.show()\n",
        "plt.savefig('Baseline, Prediction and Actuals.png', format='png')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:54:06.601818Z",
          "iopub.execute_input": "2023-10-25T15:54:06.60222Z",
          "iopub.status.idle": "2023-10-25T15:54:07.029507Z",
          "shell.execute_reply.started": "2023-10-25T15:54:06.602188Z",
          "shell.execute_reply": "2023-10-25T15:54:07.02822Z"
        },
        "trusted": true,
        "id": "ZMvy5YUV02yP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate error for baseline naive model first 24 hours of test set\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
        "\n",
        "# calculate error for baseline naive model on test set\n",
        "testBaselineMAE1day = mean_absolute_error(mergeData.AggregateLoad[train_size+val_size:train_size+val_size+OUT_STEPS], NaiveForecast[train_size+val_size:train_size+val_size+OUT_STEPS])\n",
        "\n",
        "# calculate error for baseline naive model on test set\n",
        "testModelMAE1day = mean_absolute_error(mergeData.AggregateLoad[train_size+val_size:train_size+val_size+OUT_STEPS], testYhat[0,:,-1])\n",
        "\n",
        "print('testBaselineMAE1day: ', testBaselineMAE1day)\n",
        "print('testModelMAE1day: ', testModelMAE1day)\n",
        "print('Model accuracy absolute improvement: ', testBaselineMAE1day - testModelMAE1day)\n",
        "print('Model accuracy % improvement: ', (testBaselineMAE1day - testModelMAE1day) / testBaselineMAE1day * 100)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:54:07.031575Z",
          "iopub.execute_input": "2023-10-25T15:54:07.032292Z",
          "iopub.status.idle": "2023-10-25T15:54:07.044384Z",
          "shell.execute_reply.started": "2023-10-25T15:54:07.032249Z",
          "shell.execute_reply": "2023-10-25T15:54:07.042975Z"
        },
        "trusted": true,
        "id": "8wBqPNMl02yQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aggregate results for Test period: Benchmark, GRU model and actuals"
      ],
      "metadata": {
        "id": "auwuSRgf02yQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build dataset for the test dataset\n",
        "\n",
        "ds = tf.keras.utils.timeseries_dataset_from_array(\n",
        "      data=test_data,\n",
        "      targets=None,\n",
        "      sequence_length=IN_STEPS,\n",
        "      sequence_stride=1,\n",
        "      shuffle=False,\n",
        "      batch_size=32,)\n",
        "\n",
        "# get the prediction\n",
        "testYhatNormed = multi_gru_model.predict(ds)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:54:07.046302Z",
          "iopub.execute_input": "2023-10-25T15:54:07.046844Z",
          "iopub.status.idle": "2023-10-25T15:54:08.316596Z",
          "shell.execute_reply.started": "2023-10-25T15:54:07.046807Z",
          "shell.execute_reply": "2023-10-25T15:54:08.315613Z"
        },
        "trusted": true,
        "id": "xCQ2xsFd02yQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(testYhatNormed.shape)\n",
        "print(testYhatNormed)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:54:08.319226Z",
          "iopub.execute_input": "2023-10-25T15:54:08.319754Z",
          "iopub.status.idle": "2023-10-25T15:54:08.327313Z",
          "shell.execute_reply.started": "2023-10-25T15:54:08.319675Z",
          "shell.execute_reply": "2023-10-25T15:54:08.326156Z"
        },
        "trusted": true,
        "id": "7pQi6FEO02yQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Invert standardization\n",
        "testYhat = testYhatNormed * train_std.AggregateLoad + train_mean.AggregateLoad\n",
        "\n",
        "print(testYhat.shape)\n",
        "print(testYhat)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:54:08.328597Z",
          "iopub.execute_input": "2023-10-25T15:54:08.328955Z",
          "iopub.status.idle": "2023-10-25T15:54:08.341368Z",
          "shell.execute_reply.started": "2023-10-25T15:54:08.328925Z",
          "shell.execute_reply": "2023-10-25T15:54:08.340138Z"
        },
        "trusted": true,
        "id": "_-Kxva1402yR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Estimate financial impact of improved forecast"
      ],
      "metadata": {
        "id": "nrxw6FWb02yR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load pricing data\n",
        "\n",
        "Load day forward and real time wholesale electricity pricing data to help us estimate financial benefit of the best model."
      ],
      "metadata": {
        "id": "Rx165a_M02yS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.nordpoolgroup.com/en/Market-data1/Intraday/intraday-auction-uk/uk/evening-auction-17.30-bst/prices-and-volumes/half-hour/?view=table\n",
        "# https://www.nordpoolgroup.com/en/Market-data1/GB/Auction-prices/no2/hourly/?view=table\n",
        "# prices = pd.read_csv('/kaggle/input/uk-elec-prices/Elec price curves - UK Price Curves multiple days.csv', parse_dates=['Date'])\n",
        "prices = pd.read_csv('/kaggle/input/uk-elec-prices/Elec price curves - UK price curves 24-11-2-2022.csv')\n",
        "prices"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:54:08.343194Z",
          "iopub.execute_input": "2023-10-25T15:54:08.34417Z",
          "iopub.status.idle": "2023-10-25T15:54:08.386102Z",
          "shell.execute_reply.started": "2023-10-25T15:54:08.344127Z",
          "shell.execute_reply": "2023-10-25T15:54:08.384859Z"
        },
        "trusted": true,
        "id": "aU805Cy402yS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize pricing curve"
      ],
      "metadata": {
        "id": "sWLybuM102yS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Naive prediction, GRU prediction and Actuals for first 24 hours of the test set (normed values)\n",
        "len_prediction=[x for x in range(len(prices['Real Time Price']))]\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(len_prediction, prices['Day Ahead Price'], label=\"Day Ahead Price\")\n",
        "plt.plot(len_prediction, prices['Real Time Price'], 'r', label=\"Real Time Price\")\n",
        "\n",
        "plt.tight_layout()\n",
        "sns.despine(top=True)\n",
        "plt.subplots_adjust(left=0.07)\n",
        "plt.ylabel('Price (GBP/MWH)', size=15)\n",
        "plt.xlabel('Hour', size=15)\n",
        "plt.legend(fontsize=15)\n",
        "plt.title('UK Price Curve Analog: 11-24-2022', size=15)\n",
        "plt.show();\n",
        "plt.savefig('Price Curve.png', format='png')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:54:08.387378Z",
          "iopub.execute_input": "2023-10-25T15:54:08.387723Z",
          "iopub.status.idle": "2023-10-25T15:54:08.855209Z",
          "shell.execute_reply.started": "2023-10-25T15:54:08.387694Z",
          "shell.execute_reply": "2023-10-25T15:54:08.85408Z"
        },
        "trusted": true,
        "id": "IDJ165d102yT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate baseline estimate overestimate and underestimate profile\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8wbMG2LL02yT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def calculate_forecast_penalty(forecast, actual, prices):\n",
        "    # forecast is a list of 48 half-hourly forecast values, in kWh\n",
        "    # actual is a list of 48 half-hourly actual values, in kWh\n",
        "    # prices is a dataframe with 24 day-ahead and real-time wholesale electricity prices, in $/MWh\n",
        "\n",
        "    misEstDollars = []\n",
        "    dollarPenalty = 0\n",
        "    counter = 0\n",
        "\n",
        "    misEstimate = forecast - actual\n",
        "\n",
        "    for x in misEstimate:\n",
        "        priceIndex = math.floor(counter / 2) # we only have hourly pricing data\n",
        "        # print('priceIndex: ', priceIndex)\n",
        "        if x > 0:\n",
        "            # overestimate\n",
        "            dollarPenalty = x * prices.iloc[priceIndex]['Day Ahead Price']\n",
        "        elif x < 0:\n",
        "            # underestimate\n",
        "            # dollarPenalty = -x * (prices.iloc[priceIndex]['Real Time Price'] - prices.iloc[priceIndex]['Day Ahead Price'])\n",
        "            dollarPenalty = -x * (prices.iloc[priceIndex]['Real Time Price'])\n",
        "        else:\n",
        "            dollarPenalty = 0\n",
        "        misEstDollars.append(dollarPenalty / 1000) # convert MWh to kWh\n",
        "        counter += 1\n",
        "\n",
        "    print('\\nDollar penalty for misestimation each half-hour: ', misEstDollars)\n",
        "    TotalDollarPenalty = sum(misEstDollars)\n",
        "    print('\\nTotal dollar penalty for misestimation for the day: ', TotalDollarPenalty)\n",
        "    return TotalDollarPenalty, misEstDollars\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:54:08.856713Z",
          "iopub.execute_input": "2023-10-25T15:54:08.857051Z",
          "iopub.status.idle": "2023-10-25T15:54:08.866811Z",
          "shell.execute_reply.started": "2023-10-25T15:54:08.857021Z",
          "shell.execute_reply": "2023-10-25T15:54:08.865644Z"
        },
        "trusted": true,
        "id": "VAj7SXcn02yU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate financial penalty for baseline\n",
        "baselinePenalty, baselinePenaltyHourly = calculate_forecast_penalty(forecast=NaiveForecast[train_size+val_size:train_size+val_size+OUT_STEPS],\n",
        "                           actual=mergeData.AggregateLoad[train_size+val_size:train_size+val_size+OUT_STEPS],\n",
        "                           prices=prices)\n",
        "baselinePenalty"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:54:08.868526Z",
          "iopub.execute_input": "2023-10-25T15:54:08.869022Z",
          "iopub.status.idle": "2023-10-25T15:54:08.889596Z",
          "shell.execute_reply.started": "2023-10-25T15:54:08.868987Z",
          "shell.execute_reply": "2023-10-25T15:54:08.888125Z"
        },
        "trusted": true,
        "id": "gM8Giv3I02yU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate financial penalty for model\n",
        "modelPenalty, modelPenaltyHourly = calculate_forecast_penalty(forecast=testYhat[0,:,-1],\n",
        "                           actual=mergeData.AggregateLoad[train_size+val_size:train_size+val_size+OUT_STEPS],\n",
        "                           prices=prices)\n",
        "modelPenalty"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:54:08.891371Z",
          "iopub.execute_input": "2023-10-25T15:54:08.891994Z",
          "iopub.status.idle": "2023-10-25T15:54:08.91431Z",
          "shell.execute_reply.started": "2023-10-25T15:54:08.891959Z",
          "shell.execute_reply": "2023-10-25T15:54:08.913315Z"
        },
        "trusted": true,
        "id": "Txerrm8U02yU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot penalty by hour\n",
        "x = np.arange(len(modelPenaltyHourly))\n",
        "width = 0.3\n",
        "\n",
        "plt.bar(x - 0.17, baselinePenaltyHourly, width, label='Baseline')\n",
        "plt.bar(x + 0.17, modelPenaltyHourly, width, label='Model')\n",
        "plt.ylabel(f'Penalty (GBP)')\n",
        "plt.xlabel(f'Half-hour')\n",
        "_ = plt.legend()\n",
        "plt.title(f'Penalty by half-hour')\n",
        "plt.savefig('Penalty by half-hour.png', format='png')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:54:08.915581Z",
          "iopub.execute_input": "2023-10-25T15:54:08.915972Z",
          "iopub.status.idle": "2023-10-25T15:54:09.626909Z",
          "shell.execute_reply.started": "2023-10-25T15:54:08.915941Z",
          "shell.execute_reply": "2023-10-25T15:54:09.625689Z"
        },
        "trusted": true,
        "id": "CAVpTmuh02yV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelBenefit = baselinePenalty - modelPenalty\n",
        "modelBenefitPerCustomer = modelBenefit / 4987\n",
        "print('\\nBaseline penalty: ${:,.2f}'.format(baselinePenalty))\n",
        "print('Model penalty: ${:,.2f}'.format(modelPenalty))\n",
        "print('Net Model absolute benefit: ${:,.2f}'.format(modelBenefit))\n",
        "print('Net Model benefit: {:,.2f}'.format((baselinePenalty - modelPenalty) / baselinePenalty * 100), '%')\n",
        "print('Net Model benefit per customer: ${:,.2f}'.format(modelBenefitPerCustomer))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T15:54:09.629022Z",
          "iopub.execute_input": "2023-10-25T15:54:09.629898Z",
          "iopub.status.idle": "2023-10-25T15:54:09.63911Z",
          "shell.execute_reply.started": "2023-10-25T15:54:09.629852Z",
          "shell.execute_reply": "2023-10-25T15:54:09.637958Z"
        },
        "trusted": true,
        "id": "ooVapKss02yV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}